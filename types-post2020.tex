
\documentclass[a4paper,USenglish,cleveref, autoref, thm-restate]{lipics-v2019}
%This is a template for producing LIPIcs articles.
%See lipics-manual.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\bibliographystyle{plainurl}% the mandatory bibstyle

%\title{Reducibility Candidates for Truth-Table Natural Deduction}
\title{On Model-Theoretic Strong Normalization for Truth-Table Natural Deduction}
\titlerunning{SN for Truth-Table ND} %TODO optional, please use if title is longer than one line

\author{Andreas Abel
  }{Department of Computer Science,
    Gothenburg University,
    Sweden
    % \and \url{http://www.myhomepage.edu}
  }{andreas.abel@gu.se
  }{https://orcid.org/0000-0003-0420-4492
  }{(Optional) author-specific funding acknowledgements}
%TODO mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional

% \author{Joan R. Public\footnote{Optional footnote, e.g. to mark corresponding author}}{Department of Informatics, Dummy College, [optional: Address], Country}{joanrpublic@dummycollege.org}{[orcid]}{[funding]}

\authorrunning{A. Abel} %TODO mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et al.'

\Copyright{Andreas Abel} %TODO mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm

\keywords{Strong normalization} %TODO mandatory; please add comma-separated list of keywords

\category{} %optional, e.g. invited paper

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversion{A full version of the paper is available at \url{...}.}

\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

\acknowledgements{I want to thank \dots}%optional

%\nolinenumbers %uncomment to disable line numbering

%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{xspace}
\usepackage{stmaryrd}
\usepackage{dsfont} % mathds
%\usepackage{enumitem} %% not allowed, but would be needed for leftmargin
\usepackage[hang,flushmargin]{footmisc}

% https://texblog.org/2012/03/21/cross-referencing-list-items/
\makeatletter
\def\namedlabel#1#2{\begingroup
    #2%
    \def\@currentlabel{#2}%
    \phantomsection\label{#1}\endgroup
}
\makeatother

\newcommand{\bla}{\ensuremath{\mbox{$$}}}
\newcommand{\ie}{\emph{i.e.}\xspace}
\newcommand{\eg}{\emph{e.g.}\xspace}
\newcommand{\Eg}{\emph{E.g.}\xspace}
\newcommand{\loccit}{\emph{loc.\,cit.}\xspace}
\newcommand{\cf}{cf.\ }
\newcommand{\den}[2][]{\llbracket#2\rrbracket^{#1}}
\newcommand{\dent}[1]{\llparenthesis#1\rrparenthesis}
\newcommand{\To}{\ensuremath{\Rightarrow}}
%\newcommand{\todot}{\stackrel\cdot\to}
\newcommand{\todot}{\mathbin{\dot{\to}}}
\newcommand{\bN}{\ensuremath{\mathbb{N}}}
\newcommand{\dom}{\mathop{\mathrm{dom}}\nolimits}
\newcommand{\Pot}[1]{\mathcal{P}\,#1}
%\newcommand{\defiff}{:\iff}
\newcommand{\defiff}{\mathrel{{{:}{\Longleftrightarrow}}}}
\newcommand{\subst}[3]{#3[#1/#2]}
\newcommand{\tid}{\mathsf{id}}
\newcommand{\sid}{\mathds{1}}

\newcommand{\ru}{\dfrac}
\newcommand{\nru}[3]{#1\;\dfrac{#2}{#3}}
\newcommand{\rux}[3]{\dfrac{#1}{#2}\;#3}
\newcommand{\nrux}[4]{#1\;\dfrac{#2}{#3}\;#4}

% proof by cases
\newenvironment{caselist}{%
  \begin{list}{{\it Case}}{%
    %\setlength{\topsep}{2ex}% DOES NOT SEEM TO WORK
    %\setlength{\itemsep}{2ex}%
    %\setlength{\itemindent}{-2ex}%
  }%
}{\end{list}%
}
\newenvironment{subcaselist}{%
  \begin{list}{{\it Subcase}}{}%
}{\end{list}%
}
\newenvironment{subsubcaselist}{%
  \begin{list}{{\it Subsubcase}}{}%
}{\end{list}%
}

\newcommand{\nextcase}{\item~}

\newcommand{\rulename}[1]{\ensuremath{\mbox{\textsc{#1}}}\xspace}
\newcommand{\rbeta}[1]{\ensuremath{\beta\mbox{-}\mathord{#1}}\xspace}
\newcommand{\reta}[1]{\ensuremath{\eta\mbox{-}\mathord{#1}}\xspace}
\newcommand{\rintro}[1]{\ensuremath{\mathord{#1}\mbox{-\rulename{intro}}}\xspace}
\newcommand{\relim}[1]{\ensuremath{\mathord{#1}\mbox{-\rulename{elim}}}\xspace}
\newcommand{\remb}{\rulename{emb}}
\newcommand{\rexp}{\rulename{exp}}

\newcommand{\Den}[2]{\den{#1}_{#2}}
\newcommand{\Denpar}[2]{\Den{#1}{(#2)}}

\newcommand{\bu}{\ensuremath{\bullet}}
\newcommand{\Ge}{\ensuremath{\varepsilon}}
\newcommand{\Ga}{\ensuremath{\alpha}}
\newcommand{\Gd}{\ensuremath{\delta}}
\newcommand{\Gg}{\ensuremath{\gamma}}
\newcommand{\Gl}{\ensuremath{\lambda}}
\newcommand{\Gr}{\ensuremath{\rho}}
\newcommand{\Gs}{\ensuremath{\sigma}}
\newcommand{\GG}{\ensuremath{\Gamma}}
\newcommand{\GS}{\ensuremath{\Sigma}}

\newcommand{\Set}{\mathsf{Set}}

\newcommand{\tin}{\ensuremath{\mathsf{in}}}
\newcommand{\inn}[2]{\ensuremath{\tin_{#1}^{#2}}}
\newcommand{\tel}{\mathsf{el}}
\newcommand{\el}[2]{\ensuremath{\tel_{#1}^{#2}}}

\newcommand{\contract}[1][]{\mapsto_{#1}}
\newcommand{\whd}[1][]{\rhd_{#1}}
\newcommand{\red}[1][]{\longrightarrow_{#1}}
\newcommand{\inner}[1][]{\rightharpoonup_{#1}}

\newcommand{\CR}{\mathsf{CR}}
\newcommand{\cl}[1]{\overline{#1}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\SN}{\mathsf{SN}}
\newcommand{\Intro}{\mathsf{Intro}}
\newcommand{\Up}{\mathop{\Uparrow}}
\newcommand{\up}{\mathord{\uparrow}}

\newcommand{\ind}[1]{}    % _{#1}
\newcommand{\indp}[2]{#1} % (#1)_{#2}

\begin{document}

\maketitle

%TODO mandatory: add short abstract of the document
\begin{abstract}
Truth table natural deduction
\cite{geuversHurkens:icla17,geuversHurkens:types17}
(which is non-confluent) has been shown
strongly normalizing using CPS translations to parallel lambda
calculus \cite{geuversGiessenHurkens:fundinf19}.  We investigate
standard techniques such as reducibility candidates and
biorthogonality to that end.
\end{abstract}

\section{Introduction}
\label{sec:intro}

% ICLA'17
%
% Kripke semantics and completeness proof in ICLA'17 uses a classical
% meta-theory.
%
% Propositions are boolean-valued.
% ⟦c(A₁,...,Aₙ)⟧w = ⋀ { t_c(⟦A₁⟧w',...⟦Aₙ⟧w') | w' ≤ w }
%
% Completeness proof uses notion of ψ-maximal context (similar to
% classical proof using maximally consistent contexts).
%
% SN via SAT only for optimized if-then-else, which is confluent.


% TYPES'17
%
% Impredicative, elimination-based SN proof using Girard's
% reducibility candidates.
%
% Uses a notion of key reduction (weak head reduction) to define the
% expansion closure.  Instead no closure under β-reduction is needed
% (and would not hold because of the wh-expansion closure).
%
% The condition the Ne ⊆ X is redundant.
%
% Proof of Lemma 58 c.
%
% Suppose t ∈ SN and ∀t′(t −→ka t′ ⇒ t′ ∈ c(X1,...,Xn))(*).
% Let ri be a rule for c and let D ∈ SAT, p,q ∈ Term with ∀k(pk ∈ Xk)
% and ∀ₗ ∀uₗ∈Xₗ(qₗ[yₗ:=uₗ] ∈ D).
% For all t′ with t −→ka t′ we have t·ri[p;λy.q] −→ka t′·ri[p;λy.q]
% and t′·ri[p;λy.q] ∈ D by (*).  So, t·ri[p;λy.q] ∈ D and so t ∈ c(X1,...,Xn).

Recently, Geuvers and Hurkens \cite{geuversHurkens:icla17} have
observed that, departing from the truth table of a logical connective,
one can in a schematic way construct introduction and elimination
rules for that connective both for intuitionistic and classical
natural deduction.  For each line in the truth table where the
connective computes to \emph{true} one obtains an introduction rule,
and for the \emph{false} lines one obtains an elimination rule.
It is shown that these \emph{truth table natural deduction} (TTND)
calculi are equivalent to the original calculi in the sense that the
same judgements can be derived.  However, the schematic rules

Truth table natural deduction
\cite{geuversHurkens:icla17,geuversHurkens:types17}
(which is non-confluent) has been shown
strongly normalizing using CPS translations to parallel lambda
calculus \cite{geuversGiessenHurkens:fundinf19}.  We investigate
standard techniques such as reducibility candidates and
biorthogonality to that end.

\section{Intuitionistic Truth Table Natural Deduction}
\label{sec:nd}

Geuvers et al. \cite{geuversHurkens:icla17} introduced a method to derive natural
deduction proof rules from truth tables of logical connectives.
For instance, consider the truth table for implication:
\[
\begin{array}{cc|c}
  A & B & A \to B \\
\hline
  0 & 0 & 1 \\
  0 & 1 & 1 \\
  1 & 0 & 0 \\
  1 & 1 & 1 \\
\end{array}
\]
For each line where $A \to B$ holds, \eg, the second line, an
introduction rule is created where $0$-valued (or \emph{negative})
operands $A$ become premises $\Gamma.A \vdash A \to B$ and $1$-valued
(or \emph{positive}) operands $B$ become premises $\Gamma \vdash B$.
Lines like the third where $A \to B$ is false become elimination rules
with a conclusion $\Gamma \vdash C$ for an arbitrary formula $C$.
Besides the principal premise $\Gamma \vdash A \to B$, the $1$-valued
operands $A$ become premises $\Gamma \vdash A$, and the $0$-valued
operands $B$ premises $\Gamma.B \vdash D$.  This yields the following
four rules:%
%
\footnote{%
%\setlength{\leftskip}{0pt} %NO EFFECT
Natural deduction asserts the truth of a proposition $A$
  under a list of assumed propositions $\Gamma$, a context, via the
  judgement $\Gamma \vdash A$.  Derivations of such a judgement using
  proof rules form proof trees where nodes are labeled by the name of
  the applied rule and the ordered subtrees correspond to the premises
  of the rule.  Leaves are either applications of a rule that has no
  premises or references to one of the hypotheses in $\Gamma$.
\par
  We write $\Ge$ for empty lists.
  The list $\Gamma$ can be extended on the right by a proposition $A$
  using the notation $\Gamma.A$.  Following de Bruijn
  \cite{deBruijn:nameless}, we number the hypotheses from the right
  starting with zero, and a reference to a hypothesis is a
  non-negative number $i$ smaller than the length of $\Gamma$, a
  so-called de Bruijn index.  For example, de Bruijn index zero
  refers to proposition $A$ in context $\Gamma.A$.  We write $x :
  \Gamma \vdash A$ to denote a de Bruijn index $x$ pointing to
  proposition $A$ in context $\Gamma$.
\par
  In general, we use the notation $t : \Gamma \vdash A$ to state that
  $t$ is a valid proof tree, also called proof term, whose conclusion
  is the judgement $\Gamma \vdash A$.  We will only refer to terms $t$
  that correspond to a valid proof tree, thus, we consider terms as
  intrinsically typed
  \cite{alti:monadic,bentonHurKennedyMcBride:jar12}.  This choice
  however affects neither presentation nor results in this article
  very much; they apply the same to extrinsic typing.
%
}%
%
\begin{gather*}
  \ru{t : \Gamma.A \vdash A \to B \qquad
      u : \Gamma.B \vdash A \to B
    }{\inn\to{00}(t,u) : \Gamma \vdash A \to B
    }
\\[2ex]
  \ru{t : \Gamma.A \vdash A \to B \qquad
      b : \Gamma \vdash B
    }{\inn\to{01}(t,b) : \Gamma \vdash A \to B
    }
\qquad
  \ru{a : \Gamma \vdash A \qquad
      b : \Gamma \vdash B
    }{\inn\to{11}(a,b) : \Gamma \vdash A \to B
    }
\\[2ex]
  \ru{f : \Gamma \vdash A \to B \qquad
      a : \Gamma \vdash A \qquad
      t : \Gamma.B \vdash C
    }{f \cdot \el\to{10}(a,t) : \Gamma \vdash C
    }
\end{gather*}
We preferably use letters $t,u,v$ for terms with a distinguished
hypothesis (the 0th de Bruijn index)
and letters $a,b,c,d,e,f$ for terms without such.
Replacing the distinguished hypothesis in $t$ by a derivation/term $a$
is written $t[a]$.  We use letter $I$ for introduction terms, \ie,
with $\tin$ at the root, and letter $E$ for an elimination in term $f
\cdot E$, \ie, the $\tel$ part.  Heads $h$ are either variables $x$ or
introductions $I$, and each term can be written in spine form $h \cdot
E_1 \cdot \dots \cdot E_n$.  This may be written $h \cdot \vec E$.

\emph{Detour} or $\beta$ reductions can fire when an introduction is
immediately eliminated, \ie, on well-typed subterms of the form $I
\cdot E$.  For the case of implication, there are three
introduction rule that can be paired with the only elimination rule.
There are two ways in which a $\beta$ redex can fire:  Either, a
positive premise (1) of the introduction matches a negative premise
(0) of the elimination.  For the case of implication, the second
premise of the elimination $\el\to{10}$
is negative, and it can react with the
positive second premise of $\inn\to{01}$ and $\inn\to{11}$:
\[
\begin{array}{lll}
  \inn\to{\_1}(\_,b) \cdot \el\to{10}(\_,t)
    & \contract[\beta] &
  t[b]
\end{array}
\]
The other reaction is between a negative premise of the introduction
and a matching positive premise of the elimination.  In this case, the
elimination persists, but the introduction is replaced with an
instantiation of its respective negative premise.  In the case of
implication, the first premise of $\inn\to{00}$ and $\inn\to{01}$ can
be instantiated with the first premise of $\el\to{10}$:
\[
\begin{array}{lll}
  \inn\to{0\_}(u,\_) \cdot \el\to{10}(a,t)
    & \contract[\beta] &
  u[a] \cdot \el\to{10}(a,t)
\\
\end{array}
\]

The case of implication already demonstrates the inherent
non-confluence of $\beta$-reduction: the reducts of
$\inn\to{01}(u,b) \cdot \el\to{10}(a,t)$ form the critical pair
$(t[b],\ u[a] \cdot \el\to{10}(a,t))$ which can in general not be
joined.  Non-confluence excludes some techniques to show strong
normalization, \eg, those that rely on deterministic weak head
reduction.  However, Girard's reducibility candidates accommodate
non-confluent reduction, thus, his technique may be adapted to the
present situation.

\section{Model-theoretic proofs of strong normalization}
\label{sec:model}

\subsection{Preliminaries}
\label{sec:prelim}

We work with sets $\Gamma \vdash A$ of nameless well-typed terms and
weakening under order-preserving embeddings (OPE)
$\tau : \Delta \leq \Gamma$.  Here, $\tau$ witnesses that and how
$\Gamma$ is a subsequence of $\Delta$.
Then, $\Up\tau : \Delta.B \leq \Gamma.B$ be the \emph{lifted} OPE.
Further, $\up : \Gamma.B \leq \Gamma$ is the OPE for weakening by one
variable, and OPEs form a category with identity $\sid : \Gamma \leq
\Gamma$ and composition % $\_\circ\_ :
$(\Gamma \leq \Delta) \to (\Delta \leq \Phi) \to (\Gamma \leq \Phi)$
written as juxtaposition.
If $a : \Gamma \vdash A$ then
\emph{weakening} $a\tau : \Delta \vdash A$ is defined in the usual way.
In particular, $\Up$ is used to traverse under binders, for instance,
$\inn\to{01}(t,b)\tau = \inn\to{01}(t(\Up\tau),b\tau)$.

Substitutions $\sigma : \Delta \vdash \Gamma$ are defined as lists of
terms typed by list $\Gamma$ under context $\Delta$.  Parallel
substitution $a\sigma : \Delta \vdash A$ for $a : \Gamma \vdash A$ be
defined as usual.  OPEs $\tau : \Delta \leq \Gamma$ are silently
coerced to substitutions $\Delta \vdash \Gamma$ consisting only of de
Bruijn indices.
Substitutions form a category, and we reuse $\sid$ and %$\_\circ\_$
juxtaposition for
identity and substitution.
Like for OPEs, we have lifting
$\Up : (\Delta \vdash \Gamma) \to (\Delta.B \vdash \Gamma.B)$ to push
substitutions under binders.

Single substitution $t[b]$ is
an instance for parallel substitution $t\sigma$ for substitution
$\sigma = \sid.b: \Gamma \vdash \Gamma.B$ obtained from $b : \Gamma \vdash B$.

\emph{Reduction} $a \red a'$, which is defined using single substitution,
acts on same-typed terms
$a,a' : \Gamma \vdash A$ by definition.  It is closed under weakening
and substitution.  It is even closed under \emph{anti-weakening}, \ie,
if $a\tau \red a'\tau$ then also $a \red a'$.  (Not so for
substitution, of course.)
Further, reduction commutes with weakening:  If $a\tau \red b'$ then there is
$b$ with $a \red b$ and $b' = b\tau$.

Via the parallel substitution operation, the family $\_ \vdash A$ of
terms of type $A$ is a contravariant functor (\ie, presheaf) into the
category $\Set$ of sets and functions from the category of
substitutions, and thus also from its subcategory OPE.  We will work a
lot with presheafs of the latter kind, especially with families of
predicates $P_\Gamma \subseteq (\Gamma \vdash A)$ closed under
weakening, meaning if $a \in P_\Gamma$ and $\tau : \Delta \leq \Gamma$
then $a \tau \in P_\Delta$.  We call such predicates \emph{term set
  families}.
We may simply write $a \in P$ instead of $a \in P_\Gamma$ if $\Gamma$
is fixed but arbitrary or determined by the context.

Our prime example of a term set family are the strongly normalizing
terms $\SN$ given inductively by rule
\[
  \ru{(a \red \_) \subseteq \SN
    }{a \in \SN}
  .
\]
While it is formally a family of inductive predicates on well-typed terms
$a : \Gamma \vdash A$, we mostly write $a \in \SN$ instead of
$a \in \SN(\Gamma \vdash A)$ for simplicity.  The set $\SN$ is closed
under weakening, \ie, if $\tau : \Delta \leq \Gamma$ then
$a\tau \in \SN$ as well.  This follows easily from anti-weakening for
reduction.

\subsection{Semantic types and normalization proofs}

A typical model-theoretic proof of strong normalization will interpret
types $A$ by families $\A = \den A$ of strongly normalizing terms of type $A$.
To work smoothly for open terms, a further requirement on such
semantic types $\A$ is that they contain the variables, \ie,
if $x : \Gamma \vdash A$ then $x \in \A_\Gamma$.

To obtains a compositional interpretation of types, each type
constructor such as implication $A \to B$ is interpreted by a suitable
operation $\A \to \B$ on semantic types.
For pure implicational truth table natural deduction, types are formed
from uninterpreted base types $o$ (propositional variables) and
function space: $A,B ::= o \mid A \to B$.  Types are interpreted as
the following semantic types:
\[
\begin{array}{lll}
  \Den o \Gamma & = & \SN(\Gamma \vdash o) \\
  \Den{A \to B} \Gamma & = & (\den A \to \den B)_\Gamma \\
\end{array}
\]

The main structure of the normalization proofs then proceeds as follows:
Contexts $\Gamma$ are interpreted as families of sets of
substitutions.
\[
  \begin{array}{lll}
\Den \Ge \Delta & = & \Delta \vdash \Ge \\
\Den{\Gamma.A} \Delta & = & \{ \Gs.a \mid \Gs \in \Den \Gamma \Delta
                            \mbox{ and } a \in \Den A \Delta \}
  \end{array}
\]
Thanks to the requirement that the variables inhabit the semantic
types, each context can be valuated by the identity substitution:
\begin{lemma}[Identity substitution]
  \label{lem:id}
  $\sid \in \Den \Gamma \Gamma$.
\end{lemma}
\begin{proof}
  By induction on $\Gamma$.  In case $\Gamma.A$, we have
  $\sid \in \Den \Gamma \Gamma$ by induction hypothesis, thus, by
  weakening, ${\up} \in \Den\Gamma{\Gamma.A}$.  Further, the 0th de
  Bruijn index $x_0 \in \Den A {\Gamma.A}$.
  Thus $(\up.x_0) = \sid \in \Den{\Gamma.A}{\Gamma.A}$.
\end{proof}

The main theorem shows that each well-typed term inhabits the corresponding semantic type:
\begin{theorem}[Fundamental theorem of logical predicates]
  \label{thm:fund}
  If $a : \Gamma \vdash A$ and $\Gs \in \Den \Gamma \Delta$ then $a
  \sigma \in \Den A \Delta$.
\end{theorem}
Normalization is then a direct consequence:
\begin{corollary}[Strong normalization]
  If $a : \Gamma \vdash A$ then $a \in \SN$.
\end{corollary}
\begin{proof}
  By \Cref{thm:fund} with \Cref{lem:id}, $a\, \sid = a \in \Den A
  \Gamma$, thus, $a \in \SN$ since each semantic type contains only
  strongly normalizing terms.
\end{proof}

The definition of the semantic types such as $\A \to \B$ needs be
crafted such as to allow us to prove \Cref{thm:fund}.
In the next section we identify the necessary properties.

\subsection{Modelling the inference rules}

To formulate the properties that allow us to prove \Cref{thm:fund} we
introduce an auxiliary construction $\C[\A]$ %, named \emph{abstraction},
given semantic types $\A$ and $\C$, where $\A$ classifies terms of
type $A$ and $\C$ terms of type $C$.
\[
  \C[\A]_\Gamma =
  \{ t \in \Gamma.A \vdash C
     \mid t(\tau.a) \in \C_\Delta
     \mbox{ for all } \tau : \Delta \leq \Gamma
     \mbox{ and } a \in \A_\Delta
  \}
  .
\]
The \emph{abstraction}%
\footnote{Matthes \cite[Sec.~6.2]{matthes:intersection} uses the
  notation $\mathsf{S}_x(\A,\C)$ for abstraction (in a setting with
  named variables $x$).}
$\C[\A]$ is a presheaf via the weakening with the
lifted OPE:
\begin{lemma}
  If $\tau : \Delta \leq \Gamma$ and $t \in \C[\A]_\Gamma$ then
  $t(\Up\tau) : \C[\A]_\Delta$.
\end{lemma}
\begin{proof}
  Assume $\tau' : \Phi \leq \Delta$ and $a \in \A_\Phi$ and show
  $t(\Up\tau)(\tau'.a) \in \C_\Phi$.  Since $(\Up\tau)(\tau'.a) =
  \tau\tau'.a$ this follows by definition of $t \in \C[\A]_\Gamma$.
\end{proof}

Using abstraction, the properties of the semantic implication $\A \to
\B$ can be mechanically obtained from the inference rules connected to
implication.
\begin{itemize}%[leftmargin=3em] %enumitem
\setlength{\itemindent}{2.7em}

\item[\namedlabel{it:in00}{\rm(\inn\to{00})}]
  If $t \in (\A \to \B)[\A]$ and $u \in (\A \to \B)[\B]$ then
  $\inn\to{00}(t,u) \in \A \to \B$.

\item[\namedlabel{it:in01}{\rm(\inn\to{01})}]
  If $t \in (\A \to \B)[\A]$ and $b \in \B$ then
  $\inn\to{01}(t,b) \in \A \to \B$.

\item[\namedlabel{it:in11}{\rm(\inn\to{11})}]
  If $a \in \A$ and $b \in \B$ then $\inn\to{11}(a,b) \in \A \to \B$.

\item[\namedlabel{it:el10}{\rm(\el\to{10})}]
  If $f \in \A \to \B$ and $a \in \A$ and $t \in \C[\B]$ then
  $f \cdot \el\to{01}(a,t) \in \C$.

\end{itemize}

Given these properties of semantic implication, we can show that
semantic types model the inference rules:

\begin{proof}[Proof of \Cref{thm:fund}]
  By induction on $t : \Gamma \vdash C$, prove $t\Gs \in \Den C \Delta$ for
  all $\Gs \in \Den \Gamma \Delta$.
  In case of a variable $t = x$, we have
  $x\Gs \in \Den{\Gamma(x)}\Delta$ by assumption on $\Gs$.

  The other cases are covered by the assumptions on semantic
  implication.  For instance, consider:
  \[
  \ru{t : \Gamma.A \vdash A \to B \qquad
      b : \Gamma \vdash B
    }{\inn\to{01}(t,b) : \Gamma \vdash A \to B
    }
  \]
  By induction hypothesis $b\sigma \in \Den B \Delta$ and
  for all $\tau : \Phi \leq \Delta$ and $a \in \Den A \Phi$
  further $t(\sigma\tau.a) \in \Den{A \to B}\Phi$,
  since $\sigma\tau \in \Den\Gamma\Phi$.
  Hence,
  $t(\Up\sigma) \in (\den{A \to B})[\den A]_\Delta$.  By property
  \ref{it:in01}, if follows that
  $\inn\to{01}(t,b)\sigma = \inn\to{01}(t(\Up\sigma),b\sigma) \in \Den{A \to B}\Delta$.
\end{proof}

\subsection{Flavors of semantic types}
\label{sec:flavors}

There are three main methods how to construct semantic types for
strong normalization proofs.
\begin{enumerate}
\item Saturated sets following Tait
  \cite{tait:functionalsFiniteTypeI}, see \eg the exposition by Luo
  \cite{luo:thesis}.
  This technique requires semantic types to be closed under weak head
  expansion and is only known to work for deterministic weak head
  reduction.  However, truth table natural deduction has
  non-deterministic and even non-confluent weak head reduction.
\item Reducibility candidates following Girard
  \cite{girard:thesis,girardLafontTaylor:proofsAndTypes}.  We apply
  this method in \Cref{sec:cr}
\item Biorthogonals that have been used in SN proofs for
  $\lambda$-calculi for classical logic, e.g. by Parigot \cite{parigot:jsl97},
  and in SN proofs for the monadic meta-language by Lindley and Stark
  \cite{lindleyStark:tlca05}. We shall turn to these in \Cref{sec:biortho}.
\end{enumerate}

\section{Reducibility Candidates}
\label{sec:cr}

Girard's reducibility candidates are a flavor of semantic types that
can show strong normalization also for non-confluent rewrite relations
such as reduction in truth-table natural deduction.

When defining the semantic versions of the logical connectives such as
$\A \to \B$, we have the choice to base the definition either on the
introduction rules or the elimination rules.
\footnote{See Matthes' \cite[Section 6.2]{matthes:intersection}
  systematic exposition of introduction-based vs.\ elimination-based
  definition of semantic types (in the context of the saturated sets method).}
We will study both
approaches, but first, we recapitulate the definition of reducibility
candidates.

Let $\Intro$ be the term set of introductions, \ie, the terms of
the form $\tin^{\vec b}_c(\vec t)$.  This is clearly closed under
weakening and anti-weakening.

A \emph{reducibility candidate} $\A$ for a type $A$
is a term set family
%  is a context-indexed
% family of predicates on terms of type $A$, written as sets,
with the following properties:
\begin{itemize}%[leftmargin=3em]
\setlength{\itemindent}{2.7em}

% \item[\namedlabel{it:cr0}{CR0}]
%   If $a \in \A_\Gamma$ and $\tau : \Delta \leq \Gamma$ then
%   $a\tau \in \A_\Delta$.

\item[\namedlabel{it:cr1}{CR1}]
  $\A\ind\Gamma \subseteq \SN$.

\item[\namedlabel{it:cr2}{CR2}]
  If $a \in \A\ind\Gamma$ and $a \red a'$ then $a' \in \A\ind\Gamma$.

\item[\namedlabel{it:cr3}{CR3}]
  For $a : \Gamma \vdash A$,
  % if $a \in \SN \setminus \Intro$
  if $a \not\in \Intro$
  and $(a \red \_) \subseteq \A\ind\Gamma$, then $a \in \A\ind\Gamma$.

\end{itemize}
We write $\A \in \CR$ if $\A$ is a term set family satisfying CR1-3.
It is easy to see that $\SN \in \CR$.
If $\A$ satisfies only CR1/2, it shall be called a \emph{precandidate}.

Term set abstraction operates on precandidates:
\begin{lemma}[Abstraction]
\label{lem:abs}
  Let $\A_\Gamma$ be inhabited for any $\Gamma$.
  If $\C$ is a precandidate, so is $\C[\A]$.
 % satisfies CR1/2 and is
 %  closed under lifted weakening (almost \ref{it:cr0}).
\end{lemma}
\begin{proof}
  \ref{it:cr1} holds by non-emptiness of $\A$.  Given $t \in \C[\A]_\Gamma$ and
  arbitrary $a \in \A_\Gamma$ we have $t[a] \in \C_\Gamma$.  In
  particular, $t[a] \in \SN$, and thus, $t \in \SN$.

  \ref{it:cr2} relies on the closure of reduction
  under substitution:  Assume $\C[\A]_\Gamma \ni t \red t'$ and $\tau
  : \Delta \leq \Gamma$ and $a \in \A_\Delta$.  To show $t'(\tau.a)
  \in \C_\Delta$ observe that $t(\tau.a) \in \C_\Delta$ and that \ref{it:cr2}
  holds for $\C$.
\end{proof}


\subsection{Elimination-based approach}
\label{sec:elimbased}

Geuvers and Hurkens \cite{geuversHurkens:types17} base the semantic
definition of the logical connective on the elimination rules.
A term inhabits a semantic type if it can be soundly eliminated by all
possible eliminations for that type.
In case of implication, % \fbox{$f \in (\A \to \B)_\Gamma$} iff
\[
  f \in (\A \to \B)_\Gamma
  \iff
  \forall \C \in \CR, \,
  a \in \A_\Gamma, \,
  t \in \C[\B]_\Gamma.\
  f \cdot \el\to{10}(a,t) \in \C_\Gamma .
\]
This definition can be mechanically derived from the elimination rules
of implication, which is the single rule:
\[
  \ru{f : \Gamma \vdash A \to B \qquad
      a : \Gamma \vdash A \qquad
      t : \Gamma.B \vdash C
    }{f \cdot \el\to{10}(a,t) : \Gamma \vdash C
    }
\]
In case of several elimination rules, the definition of the semantic
type has to require the closure under all rules \cite{geuversHurkens:types17}.

Note the impredicative quantification over all reducibility candidates
$\C$, which requires an impredicative meta-theory to formalize this
definition.  Such an impredicative quantification is not required in
the introduction-based approach (see \Cref{sec:introbased}).

The elimination-based approach gives us the soundness of the
elimination rules for free.
\begin{lemma}[Elimination]
  If $f \in \A \to \B$ and $a \in \A$ and $t \in \C[\B]$ then
  $f \cdot \el\to{10}(a,t) \in \C$.
  (Property \ref{it:el10}.)
\end{lemma}
\begin{proof}
  By definition of $\A \to \B$.
\end{proof}

Soundness of the introduction rules requires some work.
\begin{lemma}[Introduction]
  Properties \ref{it:in00}, \ref{it:in01} and \ref{it:in11} hold for
  $\A \to \B$.
\end{lemma}
\begin{proof}
  We show property \ref{it:in01}, the others are analogous.  Assume
  $t \in (\A \to \B)[\A]\ind\Gamma$ and $b \in \B\ind\Gamma$ and show
  $\inn\to{01}(t,b) \in \indp{\A \to \B}{\Gamma}$.  To this end, assume
  $\C \in \CR$ and $a \in \A\ind\Gamma$ and $u \in \C[\B]\ind\Gamma$ and
  show $v := \inn\to{01}(t,b) \cdot \el\to{10}(a,u) \in \C\ind\Gamma$ by
  induction on $t,b,a,u \in \SN$ (obtained by \ref{it:cr1}).

  Since $v$ is not an introduction we shall utilize \ref{it:cr3} for
  $\C$.  Therefore, we have to show that all reducts of $v$ are
  already in $\C\ind\Gamma$.

  If reduction happens in subterm $b$, so $b \red b'$, we can apply
  the induction hypothesis on $b' \in \SN$, since $b' \in \B\ind\Gamma$
  by \ref{it:cr2}.  Reduction in one of the other subterms $t,a,u$ of
  $v$ is treated analgously.

  It remains to cover the $\beta$-reductions at the root, which are
  $v \red u[b]$ and $v \red t[a] \cdot \el\to{10}(a,u)$.
  We have $u[b] \in \C\ind\Gamma$ by assumptions on $u$ and $b$.  Further, since
  $t[a] \in \indp{\A \to \B}{\Gamma}$, by definition $t[a] \cdot
  \el\to{10}(a,u) \in \C\ind\Gamma$.
\end{proof}

Strong normalization now follows according to \Cref{sec:model}.


\subsection{Introduction-based approach}
\label{sec:introbased}

Instead of the impredicative elimination-based definition of sematic
types like $\A \to \B$, we can base the definition on the introduction
rules.  The rough idea is that elements of $\A \to \B$ can be
introduced by any of $\inn\to{00}$, $\inn\to{01}$, and
$\inn\to{11}$---this is a union of reducibility candidates.
However, since the first two of these need already the implication
they introduce, the construction of a least fixed-point is required.


Note that the union $\A \cup \B$ of two reducibility candidates $\A$
and $\B$ preserves CR1/2, but not \ref{it:cr3}.
However,
property \ref{it:cr3} can be forced by the following closure operation $\cl\A$
on a term set $\A \subseteq \Gamma \vdash A$.
\begin{gather*}
  \nru{\remb
    }{a \in \A
    }{a \in \cl\A
    }
\qquad
  \nru{\rexp
     }{a : \Gamma \vdash A \qquad
       % a \in \SN \setminus \Intro \qquad
       a \not\in \Intro \qquad
       (a \red \_) \subseteq \cl\A
     }{a \in \cl\A}
\end{gather*}
The closure operation lifts pointwise to families
$\A_\Gamma \subseteq \Gamma \vdash A$ of term sets.
\begin{lemma}
  If $a \in \cl\A_\Gamma$ and $\tau : \Delta \leq \Gamma$ then
  $a \tau \in \cl\A_\Delta$.
\end{lemma}
\begin{proof}
  By induction on $a \in \cl\A_\Gamma$.  In case $a \in \A_\Gamma$
  (\remb) use the functoriality of $\A$ and \remb.
  In case \rexp, \ie, $a \in \SN(\Gamma \vdash A)
  \setminus \Intro$ and $(a \red\_) \subseteq \cl\A_\Delta$ we first
  have $a \tau \in \SN(\Delta \vdash A) \setminus \Intro$.  If $a\tau
  \red b'$ then there is $b$ with $a \red b$ and $b' = b\tau$, and by
  induction hypothesis $b\tau \in \cl\A_\Delta$.  Thus $a\tau \in
  \cl\A_\Delta$ by \rexp.
\end{proof}

\begin{lemma}[Saturation]
  % If $\A$ satisfies CR0-2, then $\cl\A$ is a reducibility candidate.
  $\cl\A$ is a reducibility candidate for any precandidate $\A$.
\end{lemma}
\begin{proof}
  \ref{it:cr3} is forced by the closure operation.
  Closure under reduction (\ref{it:cr2}) and preservation of SN
  (\ref{it:cr1}) are proven by induction on $t \in \cl\A$,
  the latter using that $t \in \SN$ when all its reducts are.
  % and preservation of \ref{it:cr1} and
  % \ref{it:cr2} is immediate.
  % \ref{it:cr0} follows again from anti-weakening of reduction, and that being
  % an introduction is not affected by weakening or anti-weakening.
\end{proof}

% Note that the union $\A \cup \B$ preserves CR1/2, but not \ref{it:cr3}; thus,
% to obtain a reducibility candidate from the union of two such
% candidates we need to apply the closure operation in general.

% Given two term set families $\A$ and $\X$ for types $A$ and $X$,
% resp., let $\X[\A]$ be the term set family defined by
% \[
%   \X[\A]_\Gamma =
%   \{ t \in \Gamma.A \vdash X
%      % t \in \SN(\Gamma.A \vdash X)
%      \mid t(\tau.a) \in \X_\Delta
%      \mbox{ for all } \tau : \Delta \leq \Gamma
%      \mbox{ and } a \in \A_\Delta
%   \}
%   .
% \]
% Herein, $\tau.a : \Delta \vdash \Gamma.A$ is obtained by turning
% $\tau$ into a substitution and extending it by $a$.
% Clearly, $\X[\A]$ is monotone in $\X$. (It is also antitone in $\A$, but we
% shall not utilize that.)

% \begin{lemma}[Abstraction]
%   If $\A$ and $\X$ are reducibility candidates, so is $\X[\A]$.
% \end{lemma}
% \begin{proof}
%   \ref{it:cr0} is guaranteed by the \emph{Kripke}-style definition of $\X[\A]$.
%   \ref{it:cr1} holds by definition, and \ref{it:cr2} relies on the closure of reduction
%   under substitution.

%   For \ref{it:cr3}, let $t \in \SN(\Gamma.A \vdash X) \setminus \Intro$ and
%   $(t \red \_) \subseteq \X[\A]_\Gamma$.
%   % We need to show that $t \in \X[\A]_\Gamma$.  In case that $t$ is de
%   % Bruijn index 0 (and thus X = A)
%   Further, to show that $t \in \X[\A]_\Gamma$, assume
%   $\tau : \Delta \leq \Gamma$ and $a \in \A_\Delta$ and show
%   $t(\tau.a) \in \X_\Delta$.
%   By \ref{it:cr3} for $\X$, we first need to show that $t(\tau.a) \not\in
%   \Intro$.  Since $t \not\in\Intro$, the only possibility for
%   $t(\tau.a) \in \Intro$ is that $t : \Gamma.A \vdash X$ is the 0th de Bruijn index.
%   However, this is excluded by the precondition $A \not=X$.
%   Then, we show $t(\tau.a) \in \SN$
% \end{proof}

% \begin{lemma}[Abstraction]
% \label{lem:abs}
%   Let $\A_\Gamma$ be inhabited for any $\Gamma$.
%   If $\X$ is a precandidate, then so is $\X[\A]$.
%  % satisfies CR1/2 and is
%  %  closed under lifted weakening (almost \ref{it:cr0}).
% \end{lemma}
% \begin{proof}
%   \ref{it:cr1} holds by non-emptiness of $\A$.  Given $t \in \X[\A]_\Gamma$ and
%   arbitrary $a \in \A_\Gamma$ we have $t[a] \in \X_\Gamma$.  In
%   particular, $t[a] \in \SN$, and thus, $t \in \SN$.

%   \ref{it:cr2} relies on the closure of reduction
%   under substitution:  Assume $\X[\A]_\Gamma \ni t \red t'$ and $\tau
%   : \Delta \leq \Gamma$ and $a \in \A_\Delta$.  To show $t'(\tau.a)
%   \in \X_\Delta$ observe that $t(\tau.a) \in \X_\Delta$ and that \ref{it:cr2}
%   holds for $\X$.
% %
%   % For closure under lifted weakening, assume $t \in \X[\A]_\Gamma$ and
%   % $\tau' : \Gamma' \leq \Gamma$ and show $t(\Up\tau') \in \X[\A]_{\Gamma'}$.
%   % (Note that $t : \Gamma.A \vdash X$ and $\Up\tau : \Gamma'.A \leq
%   % \Gamma.A$.)
%   % Assume $\Delta \leq \Gamma'$ and $a \in \A_\Delta$ and show
%   % $t(\Up\tau')(\tau.a) \in \X_\Delta$.  Since $t(\Up\tau')(\tau.a) =
%   % t(\tau'\tau.a)$ and $\tau'\tau : \Delta \leq \Gamma$ we conclude by
%   % $t \in \X[\A]_\Gamma$.
% %
%   % \ref{it:cr0} is guaranteed by the \emph{Kripke}-style definition of $\X[\A]$:
%   % Let $t \in \X[\A]_\Gamma$ and $\tau' : \Gamma' \leq \Gamma$ to show
%   % $t\tau' \in \X[\A]_{\Gamma'}$, assume $\tau : \Delta \leq \Gamma'$
%   % and $a \in \A_\Delta$ and show $t\tau'(\tau,a) \in \X_\Delta$.
% \end{proof}

We may now define a notion of function space on reducibility
candidates based on the introduction rules for implication.  Since
introduction rules are ``recursive'' in general, \ie, may mention the
principal formula in the subsequent of a premise, we need to employ
the least fixed-point operation $\mu$ for monotone operators on the
lattice of reducibility candidates.
We define $\A \to \B = \mu\F$ where
\[
  \F(\X)_\Gamma =
  \cl{\{
    \inn\to{00}(t,u),
    \inn\to{01}(t,b),
    \inn\to{11}(a,b) \mid
      a \in \A_\Gamma,
      b \in \B_\Gamma,
      t \in \X[\A]_\Gamma,
      u \in \X[\B]_\Gamma
  \}}
\]
This operation acts on reducibility candidates:
\begin{lemma}[Function space]
  \label{lem:fun}
  If $\A$ and $\B$ are reducibility candidates, so is $\A \to \B$.
\end{lemma}
\begin{proof}
  It is sufficient to show that $\F$ acts on reducibility candidates.
  Since \ref{it:cr3} is forced, it is sufficient that $\F(\X)$ is a
  precandidate for any candidate $\X$, and this follows mostly from
  \Cref{lem:abs} and the candidateship of $\A$ and $\B$.
  % \ref{it:cr0} is immediate,
  \ref{it:cr1} follows since any reduction of an introduction
  needs to happen in one of the arguments of $\tin$, which are SN.
  \ref{it:cr2} follows by the same observation.
\end{proof}

By definition, $\A \to \B$ models the introduction rules for
implication:
properties \ref{it:in00}, \ref{it:in01} and \ref{it:in11}.
For the elimination rule, property \ref{it:el10}, we have to do a bit of work.
\begin{lemma}[Function elimination]
  \label{lem:app}
  Let $\A,\B,\C$ be candidates.
  If $f \in \indp{\A \to \B}{\Gamma}$ and $a \in \A\ind\Gamma$ and
  $u \in \C[\B]\ind\Gamma$ then $f \cdot E \in \C$
  where $E = \el\to{10}(a,u)$.
\end{lemma}
\begin{proof}
  By main induction on $f \in \indp{\A \to \B}{\Gamma}$.
  \begin{caselist}

    \nextcase $f \not\in \Intro$ and $f \red f'$ implies
    $f' \in \indp{\A \to \B}{\Gamma}$:
    We show $f \cdot E \in \C$ by side induction on $E \in \SN$ via \ref{it:cr3}.
    First, $f \cdot E \not\in\Intro$.
    Assume $f \cdot E \red c$.  Since $f$ is not a introduction, we
    have either $f \red f'$ or $E \red E'$.  In the first case, by
    main induction hypothesis, $f' \cdot E \in \C$.
    In the second case, $f \cdot E' \in \C$ by side induction hypothesis.
    In any case, $c \in \C$.  Since $c$ was arbitrary, $f \cdot E \in
    \C$ by \ref{it:cr3}.

    \nextcase $f = \inn\to{00}(t_1,t_2)$ where
    $t_1 \in (\A \to \B)[\A]\ind\Gamma$ and
    $t_2 \in (\A \to \B)[\B]\ind\Gamma$.
    We show $f \cdot E \in \C$ by side induction on $t_1,t_2,E \in
    \SN$ via \ref{it:cr3}.
    Given $f \cdot E \red c$, there are three cases.  Either $c = f' \cdot
    E$ with $f \red f'$ or $c = f \cdot E'$ with $E \red E'$ or $c =
    t_1[a] \cdot E$.  The first two cases are handled by the side
    induction hypotheses, the last case by main induction hypothesis
    on $t_1[a] \in \indp{\A \to \B}{\Gamma}$.

    \nextcase $f = \inn\to{01}(t_1,b)$ where
    $t \in (\A \to \B)[\A]\ind\Gamma$ and
    $b \in \B\ind\Gamma$.
    We show $f \cdot E \in \C$ by side induction on $t,b,E \in
    \SN$ via \ref{it:cr3}.
    Given $f \cdot E \red c$, there are four cases.  Either $c = f' \cdot
    E$ with $f \red f'$ or $c = f \cdot E'$ with $E \red E'$ or $c =
    t[a] \cdot E$ or $c = u[b]$.  The first two cases are handled by the side
    induction hypotheses, the butlast case by main induction hypothesis
    on $t[a] \in \indp{\A \to \B}{\Gamma}$, and the last case by assumption
    $u \in \C[\B]\ind\Gamma$.

    \nextcase $f = \inn\to{11}(a',b)$ where
    $a' \in \A\ind\Gamma$ and
    $b \in \B\ind\Gamma$.
    We show $f \cdot E \in \C$ by side induction on $a',b,E \in
    \SN$ via \ref{it:cr3}.

    Given $f \cdot E \red c$, there are three cases.  Either
    $c = f' \cdot E$ with $f \red f'$ or $c = f \cdot E'$ with
    $E \red E'$ or $c = u[b]$.  The first two cases are handled by the
    side induction hypotheses and the last case by
    assumption $u \in \C[\B]\ind\Gamma$.
  \popQED
  \end{caselist}
\end{proof}

% The rest, interpretation of types and contexts and the fundamental
% theorem is standard, showing the strong normalization.

% For pure implicational truth table natural deduction, types are formed
% from uninterpreted base types $o$ (propositional variables) and
% function space: $A,B ::= o \mid A \to B$.  Types are interpreted as
% the following reducibility candidates:
% \[
% \begin{array}{lll}
%   \Den o \Gamma & = & \SN(\Gamma \vdash o) \\
%   \Den{A \to B} \Gamma & = & (\den A \to \den B)_\Gamma \\
% \end{array}
% \]
% Contexts $\Gamma$ are interpreted as families of sets of
% substitutions.
% \[
%   \begin{array}{lll}
% \Den \Ge \Delta & = & \Delta \vdash \Ge \\
% \Den{\Gamma.A} \Delta & = & \{ \Gs.a \mid \Gs \in \Den \Gamma \Delta
%                             \mbox{ and } a \in \Den A \Delta \}
%   \end{array}
% \]
% Each well-typed term inhabits the corresponding semantic type:
% \begin{theorem}[Fundamental theorem of logical predicates]
%   \label{thm:fund}
%   If $a : \Gamma \vdash A$ and $\Gs \in \Den \Gamma \Delta$ then $a
%   \sigma \in \Den A \Delta$.
% \end{theorem}
% \begin{proof}
%   By induction on $a : \Gamma \vdash A$.
%   For variables, this follows by assumption on $\Gs$, for implication
%   introductions, by definition of $\A \to \B$, and for implication
%   elimination by \Cref{lem:app}.
% \end{proof}

% \begin{lemma}[Identity substitution]
%   \label{lem:id}
%   $\sid \in \Den \Gamma \Gamma$.
% \end{lemma}
% \begin{proof}
%   By induction on $\Gamma$.  In case $\Gamma.A$, we have
%   $\sid \in \Den \Gamma \Gamma$ by induction hypothesis, thus, by
%   weakening, ${\up} \in \Den\Gamma{\Gamma.A}$.  Further, the 0th de
%   Bruijn index $x_0 \in \Den A {\Gamma.A}$ by \ref{it:cr3} (it is SN and has no
%   reducts).  Thus $(\up.x_0) = \sid \in \Den{\Gamma.A}{\Gamma.A}$.
% \end{proof}

% \begin{corollary}[Strong normalization]
%   If $a : \Gamma \vdash A$ then $a \in \SN$.
% \end{corollary}
% \begin{proof}
%   By \Cref{thm:fund} with \Cref{lem:id}, $a\, \sid = a \in \Den A
%   \Gamma$, thus, $a \in \SN$ by \ref{it:cr1}.
% \end{proof}

The pattern outlined here for implication generalizes to arbitrary
connectives given by truth tables.  Each connective is interpreted as
an operation on candidates, using the least fixed-point of the closure
of the term set generated by the introductions.  Each elimination then
has to be proven sound in a lemma similar to \Cref{lem:app}.

Geuvers et al.\ also present permutation reductions.  In the next
section, we study the extension of the normalization argument to
permutations.

\section{Permutation Reductions}
\label{sec:perm}

Outer eliminations can be shifted into the negative branches of inner
eliminations.  We write
$h \cdot E \cdot E' \contract[\pi] h \cdot E\{E'\}$ for a permutation
contraction.  The composition $E\{E'\}$ of eliminations moves a weakened
version of $E'$ to the negative branches of $E$.  In the case of
implication, we have
\[
  \el\to{10}(a,u) \{ E' \} = \el\to{10}(a,u \cdot E' \up)
\]
where $\up : \Gamma.B \leq \Gamma$ and
$E' \up$ shall denote the weakening of elimination $E'$ by $\up$.
In particular, $\el\to{10}(a',u') \up = \el\to{10}(a' \up, u' (\Up\up))$.

Just throwing permutation reductions into the mix and replaying the SN
proof for $\beta$ does not work.  The proof of \Cref{lem:app} relies
on the fact that if $f \cdot E \red c$ and $f \not\in \Intro$ then
either $f \red f'$ or $E \red E'$, but the structure of the
elimination $f \cdot E$ is preserved.  However, with permutations, in
case $f = f_0 \cdot E_0$ it could be that $c = f_0 \cdot E_0\{E\}$.
This reduction is not covered by any induction hypothesis.

We cannot arbitrarily tighten the restriction $\_ \not\in \Intro$ in
the formulation of \ref{it:cr3}, since \ref{it:cr3} is used in \Cref{lem:app} to
introduce terms of the shape $f \cdot E$
into a reducibility candidate $\C$.  Such terms need to satisfy the
restriction, therefore we cannot exclude $\pi$-redexes in general: a
priori, $f \cdot E$ could be a $\pi$-redex.

TODO: move definition of elimination typing here (or even further up) and
prove (recall) strong normalization (and confluence) of $\pi$ spine
reduction $\whd[\pi]$ where
\[
  \vec E \cdot E_1 \cdot E_2 \cdot \vec E'
  \whd[\pi]
 \vec E \cdot E_1\{E_2\} \cdot \vec E'
 .
\]

\section{Biorthogonals}
\label{sec:biortho}

Since the reducibility candidate method does not immediately extend to
permutations, we turn to a more powerful technique: biorthogonals.
Lindley and Stark \cite{lindleyStark:redComput} have observed that
biorthogonals (``$\top\top$-lifting'') deal well with the permutation
reduction for the monadic bind in a strong normalization proof for the
monadic meta-language.  We shall thus adapt this technique, although
it is more demanding on our meta-theory, requiring greatest
fixed-points of non-strictly positive operators.  This is covered by
Knaster and Tarski's fixed-point theorem \cite{tarski:fixpoint}, but
not readily available in type-theoretic proof assistants like Coq
\cite{coq:8120} and
Agda \cite{agda:261}.

In the following, when we speak of context-indexed families, we
implicitly assume that the family is closed under weakening in analogy
to \ref{it:cr0}.

Semantic types $\A$ shall now be context-indexed families of sets of
evaluation contexts $\vec E$, and we write $a \perp \A_\Gamma$ to
characterize a term $a : \Gamma \vdash A$ as classified by semantic
type $\A$.  The orthogonality relation $\perp$ is defined as
\[
  a \perp \A_\Gamma \defiff
  a \in \A_\Gamma^\perp \defiff
  a \cdot \vec E \in \SN \mbox{ for all } \vec E \in \A_\Gamma
  % \forall \vec E \in \A_\Gamma, a \cdot \vec E \in \SN
  .
\]

To formally talk about evaluation contexts, we introduce a judgement
$E : \Gamma \mid A \vdash C$ to characterize eliminations $E$ from type $A$
into $C$, and extend it to vectors $\vec E : \Gamma \mid A \vdash C$
in the usual way:
\[
  \ru{}{\tid : \Gamma \mid A \vdash A}
\qquad
  \ru{E : \Gamma \mid A \vdash B \qquad
      \vec E : \Gamma \mid B \vdash C
    }{E \cdot \vec E : \Gamma \mid A \vdash C}
\]
Weakening $\vec E \tau$ and substitution $\vec E \sigma$ are defined
in the obvious way.

We demand of semantic types that they contain the identity evaluation
context and only contain strongly normalizing evaluation contexts.
Reductions in contexts can either be in the subterms or can be
$\pi$-contractions along the spine.

More formally, a semantic type $\A_\Gamma$ for syntactic type $A$ at
context $\Gamma$ is a set of \emph{pairs}
$(C, (\vec E : \Gamma \mid A \vdash C))$.
Then $a \perp \A_\Gamma$ is defined as
$a \cdot \vec E \in \SN(\Gamma \vdash C)$
for all $(C, \vec E : \Gamma \mid A \vdash C) \in \A_\Gamma$.
However, we typically
suppress the type component $C$ which is implicitly determined by
$\vec E$.
\begin{lemma}[Semantic types]
  Let $\A$ be a semantic type for $A$.
  \begin{enumerate}
  \item If $x : \Gamma \vdash A$ is a variable, then $x \perp
    \A_\Gamma$.
  \item $\A^\perp \subseteq \SN$.
  \item $\A^\perp$ is closed under reduction.
  \end{enumerate}
\end{lemma}
\begin{proof} \bla
  \begin{enumerate}
  \item Given $(C, \vec E) \in \A_\Gamma$ show $x \cdot \vec E \in
    \SN$.  This holds since the only reductions are in $\vec E$, which
    is required to be SN by definition of semantic types.

  \item Given $t \perp \A_\Gamma$ show $t \in \SN$.
   Since $\tid \in \A_\Gamma$, we have $t \cdot \tid = t \in \SN$.

  \item Given $t \perp \A_\Gamma$ and $t \red t'$ and $\vec E \in \A_\Gamma$ we
    have $t' \cdot \vec E \in \SN$ since $t \cdot \vec E \in \SN$ and
    $t \cdot \vec E \red t' \cdot \vec E$.
  \popQED
  \end{enumerate}
\end{proof}

\noindent
Symmetrically to $\A^\perp$, given a set of terms $\T_\Gamma \subseteq
(\Gamma \vdash A)$ we define
\[
  \T_\Gamma^\perp =
  \{ (C, \vec E : \Gamma \mid A \vdash C) \mid
  a \cdot \vec E \in \SN(\Gamma \vdash C)
  \mbox{ for all } a \in \T_\Gamma \}
  .
\]
Taking the orthogonal of a non-empty SN term set is one way to
construct a semantic type:
\begin{lemma}[Orthogonals are semantic types]
  \label{lem:orthsem}
  If $\T$ is a family of non-empty sets of strongly normalizing terms
  of type $A$, then
  $\T^\perp$ is a semantic type for type $A$.
\end{lemma}
\begin{proof}
  First, $\tid \in \T^\perp$ since $\T \subseteq \SN$.
  Then $\T^\perp \subseteq \SN$ since $\T$ is non-empty.
\end{proof}

It is well-known that orthogonality gives rise to the Galois
connection
\[
  \T^\perp \supseteq \A \iff \T \subseteq \A^\perp
\]
and biorthogonality is a closure operator both on sets of terms $\T
\subseteq \T^{\perp\perp}$ and evaluation contexts
$\A \subseteq \A^{\perp\perp}$.

The abstraction type $\X[\A]$ is now defined by
\[
  \X[\A]_\Gamma =
  \{ (C, (\vec E : \Gamma.A \mid X \vdash C))
     \mid \vec E (\tau.a) \in \X_\Delta
     \mbox{ for all } \tau : \Delta \leq \Gamma
     \mbox{ and } a \perp \A_\Delta
  \}
  .
\]
Abstraction operates on semantic types:
\begin{lemma}[Abstraction, revisited]
  \label{lem:absrev}
  If $\A$ and $\X$ are semantic types for $A$ and $X$, then $\X[\A]$
  is a semantic type for $X$.
\end{lemma}
\begin{proof}
  We first show that
  $(X, (\tid : \Gamma.A \mid X \vdash X)) \in \X[\A]_\Gamma$.
  To this end, assume $\tau : \Delta \leq \Gamma$ and $a \in
  \A_\Delta$ and show $\tid(\tau.a) \in \X_\Delta$.  This is trivial,
  since $\tid(\tau.a) = \tid$ and $\X$ is a semantic type.

  Then, assume $(C, (\vec E : \Gamma.A \mid X \vdash C)) \in
  \X[\A]_\Gamma$ and show $\vec E \in \SN$.
  Choose $\tau = \up : \Gamma.A \leq \Gamma$ and $a = x_0 \in
  \A_{\Gamma.A}$ the 0th de Bruijn index, then $\vec E (\up,x_0) =
  \vec E \in \X_{\Gamma.A}$ and hence SN.
\end{proof}
Given two semantic types $\A$ and $\B$, the function space $\A \to \B$
is defined as the \emph{greatest fixpoint} $\nu \F^\perp$ of the
pointwise orthogonal $\F^\perp$ of the operator
\[
  \F(\X)_\Gamma =
  \{
    \inn\to{00}(t,u),
    \inn\to{01}(t,b),
    \inn\to{11}(a,b) \mid
      a \perp \A_\Gamma,
      b \perp \B_\Gamma,
      t \perp \X[\A]_\Gamma,
      u \perp \X[\B]_\Gamma
  \}
  .
\]
In comparison with the reducibility candidate version in
\Cref{sec:cr}, the closure operation has been replaced by
biorthogonality, and we converted $\mu(\F^{\perp\perp})$
to $(\nu(\F^\perp)^\perp)$.  We dropped the outer orthogonalization since
we now compute sets of evaluation contexts, but now $\F$ applies
orthogonalization on $\X$.

\begin{lemma}[Function space, revisited]
  \label{lem:funrev}
  If $\A$ is a semantic type for $A$ and $\B$ one for $B$, then $\A
  \to \B$ is a semantic type for $A \to B$.
\end{lemma}
\begin{proof}
  Applying \Cref{lem:orthsem},
  it is sufficient to show that $\F(\X)$ is a family of non-empty sets
  of SN terms for semantic types $\X$.
  This is the case by assumptions on $\A$, $\B$, and $\X$.
\end{proof}

\begin{lemma}[Function introduction]
  \label{lem:funintro}
  Given
  $a \perp \A_\Gamma$ and
  $b \perp \B_\Gamma$ and
  $t \perp (\A \to \B)[\A]_\Gamma$ and
  $u \perp (\A \to \B)[\B]_\Gamma$,
  we have
    $\inn\to{00}(t,u),
     \inn\to{01}(t,b),
     \inn\to{11}(a,b) \perp (\A \to \B)_\Gamma$.
\end{lemma}
\begin{proof}
  For any of the mentioned introductions $I$ we have
  $I \in \F(\A \to \B)_\Gamma$ by definition of $\F$.
  Since biorthogonalization is a closure operator, we have
  $I \in \F(\A \to \B)^{\perp\perp}_\Gamma$ and thus
  $I \perp \F(\A \to \B)^{\perp}_\Gamma = (\A \to \B)_\Gamma$,
  since $\A \to \B$ is a fixed point of $\F^\perp$.
\end{proof}

\begin{lemma}[Function elimination, preliminary]
  \label{lem:appprelim}
  Let $\A,\B,\C$ be semantic types for $A,B,C$, resp.  If
  $a \perp \A_\Gamma$ and $u \perp \C[\B]_\Gamma$ then
  $E = \el\to{10}(a,u) \in (\A \to \B)_\Gamma$.
  % Let $\A,\B,\C$ be semantic types for $A,B,C$, resp.
  % If $f \perp (\A \to \B)_\Gamma$ and $a \perp \A_\Gamma$ and
  % $u \perp \C[\B]_\Gamma$ then $f \cdot E \perp \C$
  % where $E = \el\to{10}(a,u)$.
\end{lemma}
\begin{proof}
  By coinduction, which means that we can use the coinductive
  hypothesis $E \in (\A \to \B)_\Gamma$ after one step towards the
  goal.
  Note that $E \in \SN$ since $a,u \in \SN$.
  By unfolding of the fixed point, it is sufficient to show $E \in
  \F(\A \to \B)^\perp_\Gamma$.  This means to show $I \cdot E \in \SN$
  for any $I \in \F(\A \to \B)_\Gamma$.
  \begin{caselist}

    \nextcase $I = \inn\to{00}(t,u')$ with
    $t \perp (\A \to \B)[\A]_\Gamma$ and
    $u' \perp (\A \to \B)[\B]_\Gamma$.  We proceed by side induction on
    $t,u',E \in \SN$ and show that all possible reducts of $I \cdot E$
    are SN.
    If reduction occurs in $I$ or $E$, we use the side induction
    hypothesis.
    Otherwise $I \cdot E \contract[\beta] t[a] \cdot E$.  We have
    $t[a] \perp (\A \to \B)_\Gamma$ by assumption on $t$ and
    $E \in (\A \to \B)_\Gamma$ by the coinduction hypothesis.
    Thus, $t[a] \cdot E \in \SN$.

    \nextcase $I = \inn\to{11}(a,b)$ with $a \perp \A_\Gamma$ and
    $b \perp \B_\Gamma$.  Again, we proceed by side induction on
    $a,b,E \in \SN$ and show that all possible reducts of $I \cdot E$
    are SN.
    The only interesting reduction is
    $I \cdot E \contract[\beta] u[b] \perp \C_\Gamma$, thus $u[b] \in
    \SN$.
    Coinduction is not needed in this case.

    \nextcase $I = \inn\to{01}(t,b)$.  In this case we have two
      $\beta$-contractions of $I \cdot E$ which we handle as in the
      previous cases.
  \popQED
  \end{caselist}
\end{proof}

The previous lemma is not strong enough to justify the implication
elimination rule, as from $f \perp (\A \to \B)_\Gamma$ and $E \in (\A
\to \B)_\Gamma$ we only get $f \cdot E \in \SN$, but we need the
stronger $f \cdot E \in \C_\Gamma$.
We need the following stronger lemma.

\begin{lemma}[Function elimination, revisited]
  \label{lem:appprev}
  Let $\A,\B,\C$ be semantic types for $A,B,C$, resp.  If
  $a \perp \A_\Gamma$ and $u \perp \C[\B]_\Gamma$ and
  $E = \el\to{10}(a,u)$ and $\vec E \in \C_\Gamma$ then
  $E \cdot \vec E \in (\A \to \B)_\Gamma$.
  % Let $\A,\B,\C$ be semantic types for $A,B,C$, resp.
  % If $f \perp (\A \to \B)_\Gamma$ and $a \perp \A_\Gamma$ and
  % $u \perp \C[\B]_\Gamma$ then $f \cdot E \perp \C$
  % where $E = \el\to{10}(a,u)$.
\end{lemma}
\begin{proof}
  By coinduction, which means that we can use the coinductive
  hypothesis $E \in (\A \to \B)_\Gamma$ after one step towards the
  goal.  Note that $E \in \SN$ since $a,u \in \SN$.  By unfolding of
  the fixed point, it is sufficient to show
  $E \cdot \vec E \in \F(\A \to \B)^\perp_\Gamma$.  This means to show
  $I \cdot E \cdot \vec E \in \SN$ for any
  $I \in \F(\A \to \B)_\Gamma$.
  We do this by proving that all one-step reducts of $I \cdot E \cdot
  \vec E$ are SN.
  We know that $\pi$ spine reduction $\whd[\pi]$ is strongly
  normalizing, thus we side induct on
  $E \cdot \vec E \in \SN(\whd[\pi])$. This side induction hypothesis
  covers the case that $E \cdot \vec E \whd[\pi] \vec E'$.
  We further side induction on $I,E,\vec E \in \SN$.  By these side
  induction hypotheses, we cover the case of inner reductions, i.e., that reduction occurs in
  $I$, $E$ or $\vec E$.
  It remains to treat the cases of $I \cdot E \contract[\beta] \_$
  by distinguishing the different introduction forms $I$.
  \begin{caselist}

    \nextcase $I = \inn\to{00}(t,u')$ with
    $t \perp (\A \to \B)[\A]_\Gamma$ and
    $u' \perp (\A \to \B)[\B]_\Gamma$.

    % We proceed by a second side induction on
    % $t,u',E, \vec E \in \SN$ and show that all possible reducts of $I
    % \cdot E \cdot \vec E$
    % are SN.
    % If reduction occurs in $I$ or $E$, we use the second side induction
    % hypothesis.

    % If $E \cdot \vec E \whd[\pi] \vec E'$ we use the first side
    % induction hypothesis.

    %Otherwise
    The reduction is $I \cdot E \contract[\beta] t[a] \cdot E$.  We have
    $t[a] \perp (\A \to \B)_\Gamma$ by assumption on $t$ and
    $E \cdot \vec E \in (\A \to \B)_\Gamma$ by the coinduction hypothesis.
    Thus, $t[a] \cdot E \cdot \vec E \in \SN$.

    \nextcase $I = \inn\to{11}(a,b)$ with $a \perp \A_\Gamma$ and
    $b \perp \B_\Gamma$.
    % Again, we proceed by side induction on
    % $a,b,E, \vec E \in \SN$ and show that all possible reducts of $I
    % \cdot E \cdot \vec E$
    % are SN.
    % The only interesting reduction is
    The reduction is
    $I \cdot E \contract[\beta] u[b] \perp \C_\Gamma$, thus $u[b]
    \cdot \vec E \in \SN$.
    Coinduction is not needed in this case.

    \nextcase $I = \inn\to{01}(t,b)$.  In this case we have two
      $\beta$-contractions of $I \cdot E$ which we handle as in the
      previous cases.
  \popQED
  \end{caselist}
\end{proof}

\section{Classical Truth-Table Natural Deduction}

The biorthogonality technique should extend to a classical version of
truth-table natural deduction with Parigot-style classicality!?



\clearpage

\appendix

\section{Trash}

Recall that weak head reduction $\whd[\beta]$ is the closure of
$\beta$ contraction $\contract[\beta]$ under elimination contexts.
Formally, weak head reduction is inductively defined by the rule
\[
  \ru{a \contract[\beta] a'
    }{a \cdot \vec E \whd[\beta] a' \cdot \vec E}
\]
for any possibly empty vector $\vec E$ of eliminations.
Full $\beta$ reduction $\red[\beta]$ is the closure of $\beta$ under
arbitrary contexts.  As usual, the reflexive-transitive closure of a
relation $R$ is denoted by $R^*$.

A typical property of weak head reduction is \emph{weak standardization}
\cite{alti:PhD}, namely if $a_0 \whd a_1$ and $a_0 \red a_2$ then
either $a_1 = a_2$ or there is $a_3$ such that $a_2 \whd a_3$ and $a_1 \red^* a_3$.
Informally, this property states that weak head redexes do not get
``lost'' when performing full reduction; in particular, an inner
reduction $a_0 \red a_2$ does not destroy the redex at the root, and
it can be contracted with $a_2 \whd a_3$.
Weak standardization allows us to restrict to weak head expansion, as opposed
to full expansion, when saturating term sets in normalization proofs.

In the above formulation, the property fails immediately for
non-confluent weak head reduction, however, it can be refined as
follows.  Let \emph{inner reduction} $\inner$ be the complement of weak head
reduction relative to full reduction, in our case,
${\inner[\beta]} = {\red[\beta]} \setminus {\whd[\beta]}$.
Then weak standardization can be formulated as the following square:
% if $a_0 \whd a_1$ and $a_0 \inner a_2$ then
% there is $a_3$ such that $a_2 \whd a_3$ and $a_1 \inner^* a_3$.

\begin{lemma}[Weak head standardization for $\beta_{\to}$]
If $a_0 \whd[\beta] a_1$ and $a_0 \inner[\beta] a_2$ then
there is $a_3$ such that $a_2 \whd[\beta] a_3$ and $a_1 \inner[\beta]^* a_3$.
\end{lemma}
\begin{proof}
  Let $a_0 := I \cdot E_0 \cdot \vec E \contract[\beta] c \cdot \vec E
  =: a_1$ where
  $c$ may be of the form $t[b]$ with $t$ from $E_0$ and $b$ from $I$
  or of the form $u[a] \cdot E_0$ with $a$ from $E_0$ and $u$ from
  $I$.
  The inner reduction may occur either in $\vec E$ or in $I$ or in
  $E_0$.  In the first case is trivial, in the other two cases the
  inner reduction may occur either in context $t$ or $u$ or in the
  substituted terms $b$ or $a$ or in a term that is lost by the
  reduction.  In the latter cases, zero or more inner reductions may
  be necessary to close the square.
\end{proof}

In normalization proofs by reducibility candidates there is a closure
operation $\cl\A$ on term sets $\A$ that we adapt to our setting as
the following inductive definition:
\begin{gather*}
  \ru{a \in \A
    }{a \in \cl\A}
\qquad
  \ru{a \in \SN \setminus \Intro \qquad
      (a \whd \_) \subseteq \cl\A
    }{a \in \cl\A}
\end{gather*}
Herein, $\Intro$ denotes the set of introductions $I$ and $\SN$
denotes the set of strongly normalizing terms for the reduction
relation $\red$ under consideration.  The second rule allows us to add
new strongly normalizing non-introductions $a$ into a set as long as
all weak-head reducts are already present.  In Girard's original
formulation, \emph{all} reducts wrt.\ $\red$ need to be inspected.
This stronger requirement makes it trivial to prove that the closure
operation preserves the property \emph{closed under full reduction} of
term sets $\A$.  In our case, this closure property is salvaged by
weak standardization:
\begin{lemma}
  If $\A$ is closed under reduction, so is $\cl\A$.
\end{lemma}
\begin{proof}
  Given $a \red a'$, we show $a' \in \cl\A$ by induction on $a \in
  \cl\A$.  The base case is handled by $\A$ being closed under $\red$,
  so let us assume $(a \whd \_) \subseteq \cl\A$.  This handles the
  case of $a \whd a'$, so we may assume that $a'$ is an inner reduct
  of $a$, formally, $a \inner a'$.
  DOESN'T WORK.
\end{proof}

%%
%% Bibliography
%%

%% Please use bibtex,

\bibliography{medium}

% \appendix

\end{document}
