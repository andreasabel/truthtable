
\documentclass[a4paper,USenglish,cleveref, autoref, thm-restate]{lipics-v2019}
%This is a template for producing LIPIcs articles.
%See lipics-manual.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\bibliographystyle{plainurl}% the mandatory bibstyle

%\title{Reducibility Candidates for Truth-Table Natural Deduction}
\title{On Model-Theoretic Strong Normalization for Truth-Table Natural Deduction}
\titlerunning{SN for Truth-Table ND} %TODO optional, please use if title is longer than one line

\author{Andreas Abel
  }{Department of Computer Science,
    Gothenburg University,
    Sweden
    % \and \url{http://www.myhomepage.edu}
  }{andreas.abel@gu.se
  }{https://orcid.org/0000-0003-0420-4492
  }{(Optional) author-specific funding acknowledgements}
%TODO mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional

% \author{Joan R. Public\footnote{Optional footnote, e.g. to mark corresponding author}}{Department of Informatics, Dummy College, [optional: Address], Country}{joanrpublic@dummycollege.org}{[orcid]}{[funding]}

\authorrunning{A. Abel} %TODO mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et al.'

\Copyright{Andreas Abel} %TODO mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm

\keywords{Strong normalization} %TODO mandatory; please add comma-separated list of keywords

\category{} %optional, e.g. invited paper

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversion{A full version of the paper is available at \url{...}.}

\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

\acknowledgements{I want to thank \dots}%optional

%\nolinenumbers %uncomment to disable line numbering

%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{xspace}
\usepackage{stmaryrd}
\usepackage{dsfont} % mathds
%\usepackage{enumitem} %% not allowed, but would be needed for leftmargin
\usepackage[hang,flushmargin]{footmisc}

% https://texblog.org/2012/03/21/cross-referencing-list-items/
\makeatletter
\def\namedlabel#1#2{\begingroup
    #2%
    \def\@currentlabel{#2}%
    \phantomsection\label{#1}\endgroup
}
\makeatother

\newcommand{\bla}{\ensuremath{\mbox{$$}}}
\newcommand{\ie}{\emph{i.e.}\xspace}
\newcommand{\eg}{\emph{e.g.}\xspace}
\newcommand{\Eg}{\emph{E.g.}\xspace}
\newcommand{\loccit}{\emph{loc.\,cit.}\xspace}
\newcommand{\cf}{cf.\ }
\newcommand{\den}[2][]{\llbracket#2\rrbracket^{#1}}
\newcommand{\dent}[1]{\llparenthesis#1\rrparenthesis}
\newcommand{\To}{\ensuremath{\Rightarrow}}
%\newcommand{\todot}{\stackrel\cdot\to}
\newcommand{\todot}{\mathbin{\dot{\to}}}
\newcommand{\bN}{\ensuremath{\mathbb{N}}}
\newcommand{\dom}{\mathop{\mathrm{dom}}\nolimits}
\newcommand{\Pot}[1]{\mathcal{P}\,#1}
%\newcommand{\defiff}{:\iff}
\newcommand{\defiff}{\mathrel{{{:}{\Longleftrightarrow}}}}
\newcommand{\subst}[3]{#3[#1/#2]}
\newcommand{\tid}{\mathsf{id}}
\newcommand{\sid}{\mathds{1}}

\newcommand{\ru}{\dfrac}
\newcommand{\nru}[3]{#1\;\dfrac{#2}{#3}}
\newcommand{\rux}[3]{\dfrac{#1}{#2}\;#3}
\newcommand{\nrux}[4]{#1\;\dfrac{#2}{#3}\;#4}

% proof by cases
\newenvironment{caselist}{%
  \begin{list}{{\it Case}}{%
    %\setlength{\topsep}{2ex}% DOES NOT SEEM TO WORK
    %\setlength{\itemsep}{2ex}%
    %\setlength{\itemindent}{-2ex}%
  }%
}{\end{list}%
}
\newenvironment{subcaselist}{%
  \begin{list}{{\it Subcase}}{}%
}{\end{list}%
}
\newenvironment{subsubcaselist}{%
  \begin{list}{{\it Subsubcase}}{}%
}{\end{list}%
}

\newcommand{\nextcase}{\item~}

\newcommand{\rulename}[1]{\ensuremath{\mbox{\textsc{#1}}}\xspace}
\newcommand{\rbeta}[1]{\ensuremath{\beta\mbox{-}\mathord{#1}}\xspace}
\newcommand{\reta}[1]{\ensuremath{\eta\mbox{-}\mathord{#1}}\xspace}
\newcommand{\rintro}[1]{\ensuremath{\mathord{#1}\mbox{-\rulename{intro}}}\xspace}
\newcommand{\relim}[1]{\ensuremath{\mathord{#1}\mbox{-\rulename{elim}}}\xspace}
\newcommand{\remb}{\rulename{emb}}
\newcommand{\rexp}{\rulename{exp}}

\newcommand{\Den}[2]{\den{#1}_{#2}}
\newcommand{\Denpar}[2]{\Den{#1}{(#2)}}

\newcommand{\bu}{\ensuremath{\bullet}}
\newcommand{\Ge}{\ensuremath{\varepsilon}}
\newcommand{\Ga}{\ensuremath{\alpha}}
\newcommand{\Gd}{\ensuremath{\delta}}
\newcommand{\Gg}{\ensuremath{\gamma}}
\newcommand{\Gl}{\ensuremath{\lambda}}
\newcommand{\Gr}{\ensuremath{\rho}}
\newcommand{\Gs}{\ensuremath{\sigma}}
\newcommand{\GG}{\ensuremath{\Gamma}}
\newcommand{\GS}{\ensuremath{\Sigma}}

\newcommand{\Set}{\mathsf{Set}}

\newcommand{\x}{\mathsf{x}}
\newcommand{\tin}{\ensuremath{\mathsf{in}}}
\newcommand{\inn}[2]{\ensuremath{\tin_{#1}^{#2}}}
\newcommand{\tel}{\mathsf{el}}
\newcommand{\el}[2]{\ensuremath{\tel_{#1}^{#2}}}

\newcommand{\contract}[1][]{\mapsto_{#1}}
\newcommand{\whd}[1][]{\rhd_{#1}}
\newcommand{\red}[1][]{\longrightarrow_{#1}}
\newcommand{\inner}[1][]{\rightharpoonup_{#1}}

\newcommand{\CR}{\mathsf{CR}}
\newcommand{\cl}[1]{\overline{#1}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\SN}{\mathsf{SN}}
\newcommand{\Intro}{\mathsf{Intro}}
\newcommand{\Up}{\mathop{\Uparrow}}
\newcommand{\up}{\mathord{\uparrow}}
\newcommand{\Neut}{\mathsf{Neut}}
\newcommand{\SAT}{\mathsf{SAT}}

\newcommand{\indy}[1]{_{#1}}
\newcommand{\indyp}[2]{(#1)_{#2}}
\newcommand{\ind}[1]{}    % _{#1}
\newcommand{\indp}[2]{#1} % (#1)_{#2}

\begin{document}

\maketitle

%TODO mandatory: add short abstract of the document
\begin{abstract}
Truth table natural deduction
\cite{geuversHurkens:icla17,geuversHurkens:types17}
(which is non-confluent) has been shown
strongly normalizing using CPS translations to parallel lambda
calculus \cite{geuversGiessenHurkens:fundinf19}.  We investigate
standard techniques such as reducibility candidates and
biorthogonality to that end.
\end{abstract}

\section{Introduction}
\label{sec:intro}

% ICLA'17
%
% Kripke semantics and completeness proof in ICLA'17 uses a classical
% meta-theory.
%
% Propositions are boolean-valued.
% ⟦c(A₁,...,Aₙ)⟧w = ⋀ { t_c(⟦A₁⟧w',...⟦Aₙ⟧w') | w' ≤ w }
%
% Completeness proof uses notion of ψ-maximal context (similar to
% classical proof using maximally consistent contexts).
%
% SN via SAT only for optimized if-then-else, which is confluent.


% TYPES'17
%
% Impredicative, elimination-based SN proof using Girard's
% reducibility candidates.
%
% Uses a notion of key reduction (weak head reduction) to define the
% expansion closure.  Instead no closure under β-reduction is needed
% (and would not hold because of the wh-expansion closure).
%
% The condition the Ne ⊆ X is redundant.
%
% Proof of Lemma 58 c.
%
% Suppose t ∈ SN and ∀t′(t −→ka t′ ⇒ t′ ∈ c(X1,...,Xn))(*).
% Let ri be a rule for c and let D ∈ SAT, p,q ∈ Term with ∀k(pk ∈ Xk)
% and ∀ₗ ∀uₗ∈Xₗ(qₗ[yₗ:=uₗ] ∈ D).
% For all t′ with t −→ka t′ we have t·ri[p;λy.q] −→ka t′·ri[p;λy.q]
% and t′·ri[p;λy.q] ∈ D by (*).  So, t·ri[p;λy.q] ∈ D and so t ∈ c(X1,...,Xn).

Recently, Geuvers and Hurkens \cite{geuversHurkens:icla17} have
observed that, departing from the truth table of a logical connective,
one can in a schematic way construct introduction and elimination
rules for that connective both for intuitionistic and classical
natural deduction.  For each line in the truth table where the
connective computes to \emph{true} one obtains an introduction rule,
and for the \emph{false} lines one obtains an elimination rule.
It is shown that these \emph{truth table natural deduction} (TTND)
calculi are equivalent to Gentzen's original calculi
\cite{gentzen:natuerlichesSchliessen}
in the sense that the
same judgements can be derived.  However, the schematic rules are
sometimes unwieldy and unintuitive---for instance, in TTND there are three
introduction rules for implication since $A \to B$ is true for three
out of four valuations of $(A,B)$.  As a remedy, Geuvers and Hurkens
show how the original TTND rules can be optimized in a systematic
way.  In this article, we shall confine ourselves to the schematic,
unoptimized rules of intuitionistic TTND (ITTND).

When studying proof terms and proof normalization for ITTND, one can
observe that $\beta$-reduction---the reduction of detours, \ie, introductions followed
directly by eliminations\footnotemark---is essentially non-deterministic and even
non-confluent.
\footnotetext{Geuvers and Hurkens call detour redexes
\emph{direct intuitionistic cuts} \cite{geuversHurkens:icla17}
or $a$-redexes \cite{geuversHurkens:types17} and with van der Giessen
D-redexes \cite{geuversGiessenHurkens:fundinf19}.  We follow
Joachimski and Matthes \cite{joachimskiMatthes:rta00} and call detour
reductions simply $\beta$-reductions, as these are a generalization of
the $\beta$-reduction of $\lambda$-calculus.}%
% This non-confluence raises questions about the suitability of ITTND as
% a programming language under the Curry-Howard isomorphism.
Non-confluence poses some challenges to the proof that reduction is
terminating, the so-called strong normalization (SN) property.  In the
original presentation \cite{geuversHurkens:icla17}, the authors
confine the SN proof to ITTND with a single but universal
connective \emph{if-then-else} and the optimized inference rules for
if-then-else which yield confluent and standardizing $\beta$-reduction.  The proof
follows the \emph{saturated sets} method pioneered by Tait
\cite{tait:functionalsFiniteTypeI} which is known to rely on
standardization by using deterministic weak head
reduction.\footnote{Weak head reduction is sometimes called \emph{key
  reduction} in the context of saturated sets.}

In subsequent work \cite{geuversHurkens:types17}, the authors attack
SN for full ITTND with non-confluent $\beta$-reduction, introducing
elements of Girard's technique of \emph{reducibility candidates} (RCs)
\cite{girard:thesis,girardLafontTaylor:proofsAndTypes}.  However, this
innovative mix of Tait and Girard seems to have problems, as we shall
investigate in \Cref{sec:gap}.  We show how to remedy the problems by
returning to Girard's original definition of RCs in \Cref{sec:cr}.
The repaired proof in \Cref{sec:elimbased} relies on impredicativity
and could not be formalized in a predicative metatheory such as
Martin-Löf Type Theory \cite{MartinLoef84}.  We thus give in
\Cref{sec:introbased} a variant that
replaces the use of impredicativity by inductive definitions.

However, $\beta$-reduction is not the only form of proof optimization in ITTND.
The schematic elimination rules of ITTND have the flavor of
disjunction elimination or, more general, of the left rules of
intuitionistic sequent calculus.  Those left rules do not pose any
restriction on the formula on the right.  Likewise, eliminations in
ITTND have an arbitrary target.  In such settings, one eliminate a hypothesis to directly prove the desired conclusion.
Eliminating into an intermediate conclusion which is then eliminated
again is thus considered a detour.
Joachimski and Matthes \cite{joachimskiMatthes:rta00}
call such a detour a \emph{permutation redex} or
\emph{$\pi$-redex}\footnotemark{}
---in the context of intuitionistic sequent calculus restricted to implication.
%% subsequent eliminations
%% are unnecessary and can be considered a form of detour, called
%% \emph{permutation} or \emph{$\pi$-redexes}\footnotemark{}, for instance,
%% by Joachimski and Matthes \cite{joachimskiMatthes:rta00}
%% in the context of intuitionistic sequent calculus restricted to implication.
\footnotetext{Geuvers and Hurkens call $\pi$-redexes $b$-redexes
  \cite{geuversHurkens:types17} and, with van der Giessen, P-redexes
  \cite{geuversGiessenHurkens:fundinf19}.}%
Permutation reduction for ITTND by itself is terminating
\cite{geuversHurkens:types17}, and in \loccit it is shown that the
free combination with $\beta$-reduction, $\beta\pi$, is weakly
normalizing.  Strong normalization was left open until the joint work
of Geuvers and Hurkens
with van der Giessen \cite{geuversGiessenHurkens:fundinf19}, where SN
was established via a continuation-passing-style (CPS) translation to
the parallel simply-typed lambda calculus (parallel STLC).%
\footnote{In a first approximation, one can think of parallel STLC as STLC with explicit non-determinism.}

The change of proof strategy begs the question whether the usual
model-theoretic SN proofs could not work also for
$\beta\pi$-reduction.  While the saturated sets method applied in
a similar situation by Joackimski and Matthes
\cite{joachimskiMatthes:rta00} fails due to non-confluence of $\beta$,
Girard's RCs do not cover $\pi$.  However, there is a third popular
method, \emph{(bi)orthogonals}, that have been developed to prove SN for classical lambda-calculi which are essentially non-confluent.\footnote{Early applications of orthgonality can be found in the works of Parigot \cite{parigot:jsl97,parigot:lamsym} and Barbanera and Berardi \cite{barbanera:lamsym}.}
Biorthogonals have been successfully applied by
Lindley and Stark \cite{lindleyStark:tlca05} to prove SN for Moggi's
``monadic metalanguage'', that is STLC with introduction, elimination,
and permutation rules for the monad.  We show in \Cref{sec:biortho} that
biorthogonals, putting elimination sequences at the center of
attention, can show SN for $\beta\pi$ of ITTND.

While we limit our presentation on the implicational fragment of ITTND
for didactical purposes and convenience of exposition, our techniques
scale immediately to the general case.

\paragraph*{Overview}
%
In \Cref{sec:nd} we recapitulate Geuvers and Hurkens' construction of
intuitionistic inference rules from truthtables and the associated
$\beta$-rules.
%
In \Cref{sec:model} we present a common structure of model-theoretic
SN proofs.
%
This structure is instantiated to RCs in \Cref{sec:cr} and we present
the two ways of constructing the interpretation of the connectives:
via the elimination rules (\Cref{sec:elimbased}) and via the
introduction rules (\Cref{sec:introbased}).  Further, we take a
critical look at the proof of Geuvers and Hurkens
\cite{geuversHurkens:types17} in \Cref{sec:gap}.
%
In \Cref{sec:perm} we turn to $\pi$-reduction, laying some foundation
for the SN proof for $\beta\pi$ using orthogonality
(\Cref{sec:biortho}), which is the main contribution of this paper.
%
We conclude with a short discussion in \Cref{sec:concl}.


\section{Intuitionistic Truth Table Natural Deduction}
\label{sec:nd}

Geuvers and Hurkens \cite{geuversHurkens:icla17} introduced a method to derive natural
deduction proof rules from truth tables of logical connectives.
For instance, consider the truth table for implication:
\[
\begin{array}{cc|c}
  A & B & A \to B \\
\hline
  0 & 0 & 1 \\
  0 & 1 & 1 \\
  1 & 0 & 0 \\
  1 & 1 & 1 \\
\end{array}
\]
For each line where $A \to B$ holds, \eg, the second line, an
introduction rule is created where $0$-valued (or \emph{negative})
operands $A$ become premises $\Gamma.A \vdash A \to B$ and $1$-valued
(or \emph{positive}) operands $B$ become premises $\Gamma \vdash B$.
Lines like the third where $A \to B$ is false become elimination rules
with a conclusion $\Gamma \vdash C$ for an arbitrary formula $C$.
The premises of this elimination rule are,
besides the principal premise $\Gamma \vdash A \to B$,
a premise $\Gamma \vdash A$ for each $1$-valued operand $A$, and
a premise $\Gamma.B \vdash C$ for each $0$-valued operand $B$.
This yields the following four rules:%
%
\footnote{%
%\setlength{\leftskip}{0pt} %NO EFFECT
Additional information for the reader unfamiliar with natural deduction and proof terms:
\par
Natural deduction asserts the truth of a proposition $A$
  under a list of assumed propositions $\Gamma$, a \emph{context}, via the
  judgement $\Gamma \vdash A$.  Derivations of such judgements
  %% using proof rules
  form proof trees where nodes are labeled by the name of
  the applied proof rule and the ordered subtrees correspond to the premises
  of that rule.  Leaves are either applications of a rule that has no
  premises or references to one of the hypotheses in $\Gamma$.
\par
  We write $\Ge$ for empty lists.
  The list $\Gamma$ can be extended on the right by a proposition $A$
  using the notation $\Gamma.A$.  Following de Bruijn
  \cite{deBruijn:nameless}, we number the hypotheses from the right
  starting with zero.
  A reference to a hypothesis---a so-called \emph{de Bruijn index}---
  is a
  non-negative number $i$ strictly smaller than the length of $\Gamma$.
  For example, de Bruijn index zero, written $\x_0$,
  refers to proposition $A$ in context $\Gamma.A$.  We write $x :
  \Gamma \vdash A$ to denote a de Bruijn index $x$ pointing to
  proposition $A$ in context $\Gamma$.
\par
  In general, we use the notation $t : \Gamma \vdash A$ to state that
  $t$ is a valid proof tree, also called proof term, whose conclusion
  is the judgement $\Gamma \vdash A$.  We will only refer to terms $t$
  that correspond to a valid proof tree, thus, we consider terms as
  intrinsically typed
  \cite{alti:monadic,bentonHurKennedyMcBride:jar12}.  This choice
  however affects neither presentation nor results in this article
  very much; they apply the same to extrinsic typing.
%
}%
%
\begin{gather*}
  \ru{t : \Gamma.A \vdash A \to B \qquad
      u : \Gamma.B \vdash A \to B
    }{\inn\to{00}(t,u) : \Gamma \vdash A \to B
    }
%\\[2ex]
\qquad
  \ru{t : \Gamma.A \vdash A \to B \qquad
      b : \Gamma \vdash B
    }{\inn\to{01}(t,b) : \Gamma \vdash A \to B
    }
\\[2ex]
  \ru{f : \Gamma \vdash A \to B \qquad
      a : \Gamma \vdash A \qquad
      t : \Gamma.B \vdash C
    }{f \cdot \el\to{10}(a,t) : \Gamma \vdash C
    }
\qquad
  \ru{a : \Gamma \vdash A \qquad
      b : \Gamma \vdash B
    }{\inn\to{11}(a,b) : \Gamma \vdash A \to B
    }
\end{gather*}
As seen from these instances,
we preferably use letters $t,u,v$ for terms with a distinguished
hypothesis
%% (the 0th de Bruijn index)
and letters $a,b,c,d,e,f$ for terms without such.
Replacing the distinguished hypothesis, \ie,
the 0th de Bruijn index,
in term $t$ by a term $a$
is written $t[a]$.  We use letter $I$ for introduction terms, \ie,
such with ``$\tin$'' at the root,
and letter $E$ for an elimination in term $f \cdot E$,
\ie, the ``$\tel$'' part.  Heads $h$ are either variables $x$ or
introductions $I$, and each term can be written in spine form $h \cdot
E_1 \cdot \dots \cdot E_n$.  This may be written $h \cdot \vec E$.

\emph{Detour} or $\beta$ reductions can fire when an introduction is
immediately eliminated, \ie, on well-typed subterms of the form $I
\cdot E$.  For the case of implication, there are three
introduction rules that can be paired with the only elimination rule.
There are two ways in which a $\beta$ redex can fire:  Either, a
positive premise (1) of the introduction matches a negative premise
(0) of the elimination.  For the case of implication, the second
premise of the elimination $\el\to{10}$
is negative, and it can react with the
positive second premise of $\inn\to{01}$ and $\inn\to{11}$:
\[
\begin{array}{lll}
  \inn\to{\_1}(\_,b) \cdot \el\to{10}(\_,t)
    & \contract[\beta] &
  t[b]
\end{array}
\]
The other reaction is between a negative premise of the introduction
and a matching positive premise of the elimination.  In this case, the
elimination persists, but the introduction is replaced with an
instantiation of its respective negative premise.  In the case of
implication, the first premise of $\inn\to{00}$ and $\inn\to{01}$ can
be instantiated with the first premise of $\el\to{10}$:
\[
\begin{array}{lll}
  \inn\to{0\_}(u,\_) \cdot \el\to{10}(a,t)
    & \contract[\beta] &
  u[a] \cdot \el\to{10}(a,t)
\\
\end{array}
\]

The case of implication already demonstrates the inherent
non-confluence of $\beta$-reduction: the reducts of
$\inn\to{01}(u,b) \cdot \el\to{10}(a,t)$ form the critical pair
$(t[b],\ u[a] \cdot \el\to{10}(a,t))$ which can in general not be
joined.  Non-confluence excludes some techniques to show strong
normalization, \eg, those that rely on deterministic weak head
reduction.  However, Girard's reducibility candidates accommodate
non-confluent reduction, thus, his technique may be adapted to the
present situation.

\section{Model-theoretic proofs of strong normalization}
\label{sec:model}

In this section we explain the general format of a model-theoretic
proof of strong normalization.  We will instantiate this framework to two techniques later: reducibility candidates (\Cref{sec:cr}) and orthogonality (\Cref{sec:ortho}).

\subsection{Preliminaries}
\label{sec:prelim}

We work with sets $\Gamma \vdash A$ of nameless well-typed terms.
De Bruijn indices are written $\x_n : \Gamma.A.\Delta \vdash A$ where
$\Delta$ has length $n$.
Instead of full-fledged renaming, we confine to
weakening under order-preserving embeddings (OPE)
$\tau : \Delta \leq \Gamma$.  Here, $\tau$ witnesses that and how
$\Gamma$ is a subsequence of $\Delta$.
Then, $\Up\tau : \Delta.B \leq \Gamma.B$ be the \emph{lifted} OPE.
Further, $\up : \Gamma.B \leq \Gamma$ is the OPE for weakening by one
variable, and OPEs form a category with identity $\sid : \Gamma \leq
\Gamma$ and composition % $\_\circ\_ :
$(\Gamma \leq \Delta) \to (\Delta \leq \Phi) \to (\Gamma \leq \Phi)$
written as juxtaposition.
If $a : \Gamma \vdash A$ then
\emph{weakening} $a\tau : \Delta \vdash A$ is defined in the usual way.
In particular, $\Up$ is used to traverse under binders, for instance,
$\inn\to{01}(t,b)\tau = \inn\to{01}(t(\Up\tau),b\tau)$.

Substitutions $\sigma : \Delta \vdash \Gamma$ are defined as lists of
terms typed by list $\Gamma$ under context $\Delta$.  Parallel
substitution $a\sigma : \Delta \vdash A$ for $a : \Gamma \vdash A$ is
defined as usual.  OPEs $\tau : \Delta \leq \Gamma$ are silently
coerced to substitutions $\Delta \vdash \Gamma$ consisting only of de
Bruijn indices.
Substitutions form a category, and we reuse $\sid$ for
identity and %$\_\circ\_$
juxtaposition for substitution.
Like for OPEs, we have lifting
$\Up : (\Delta \vdash \Gamma) \to (\Delta.B \vdash \Gamma.B)$ to push
substitutions under binders.
%
Single substitution $t[b]$ is
an instance of parallel substitution $t\sigma$ for substitution
$\sigma = \sid.b : (\Gamma \vdash \Gamma.B)$ obtained from $b : \Gamma \vdash B$.

\emph{Reduction} $a \red a'$, which is defined using single substitution,
acts on same-typed terms
$a,a' : \Gamma \vdash A$ by definition.  It is closed under weakening
and substitution.  It is even closed under \emph{anti-weakening}, \ie,
if $a\tau \red a'\tau$ then also $a \red a'$.  (Not so for
substitution: it is not closed under anti-substitution, of course.)
Further, reduction commutes with weakening:  If $a\tau \red b'$ then there is
$b$ with $a \red b$ and $b' = b\tau$.

Via the parallel substitution operation, the family $\_ \vdash A$ of
terms of type $A$ is a contravariant functor (\ie, presheaf) targeting the
category $\Set$ of sets and functions.
Its source is the category of
substitutions, and thus also its subcategory OPE.  We will work a
lot with presheafs of the latter kind, especially with families of
predicates $P_\Gamma \subseteq (\Gamma \vdash A)$ closed under
weakening, meaning if $a \in P_\Gamma$ and $\tau : \Delta \leq \Gamma$
then $a \tau \in P_\Delta$.  We call such predicates \emph{term set
  families}.
We may simply write $a \in P$ instead of $a \in P_\Gamma$ if $\Gamma$
is fixed but arbitrary or can be determined by the context.

Our prime example of a term set family are the strongly normalizing
terms $\SN$ given inductively by rule
\[
  \ru{(a \red \_) \subseteq \SN
    }{a \in \SN}
  .
\]
While it is formally a family of inductive predicates on well-typed terms
$a : \Gamma \vdash A$, we mostly write $a \in \SN$ instead of
$a \in \SN(\Gamma \vdash A)$ for simplicity.  The set $\SN$ is closed
under weakening, \ie, if $\tau : \Delta \leq \Gamma$ then
$a\tau \in \SN$ as well.  This follows easily from anti-weakening for
reduction.

\subsection{Semantic types and normalization proofs}

A typical model-theoretic proof of strong normalization will interpret
types $A$ by families $\A = \den A$ of strongly normalizing terms of type $A$.
To work smoothly for open terms, a further requirement on such
semantic types $\A$ is that they contain the variables, \ie,
if $x : \Gamma \vdash A$ then $x \in \A_\Gamma$.

To obtain a compositional interpretation of types, each type
constructor such as implication $A \to B$ is interpreted by a suitable
operation $\A \to \B$ on semantic types.
For pure implicational truth table natural deduction, types are formed
from uninterpreted base types $o$ (propositional variables) and
function space: $A,B ::= o \mid A \to B$.  Types are interpreted as
the following semantic types:
\[
\begin{array}{lll}
  \Den o \Gamma & = & \SN(\Gamma \vdash o) \\
  \Den{A \to B} \Gamma & = & (\den A \to \den B)_\Gamma \\
\end{array}
\]

The main structure of the normalization proof then proceeds as follows:
Contexts $\Gamma$ are interpreted as families of sets of
substitutions.
\[
  \begin{array}{lll}
\Den \Ge \Delta & = & \Delta \vdash \Ge
\quad ( {} = \{ \sigma \mid \sigma : \Delta \vdash \Ge \})\\
\Den{\Gamma.A} \Delta & = & \{ \Gs.a \mid \Gs \in \Den \Gamma \Delta
                            \mbox{ and } a \in \Den A \Delta \}
  \end{array}
\]
Thanks to the requirement that the variables inhabit the semantic
types, each context can be valuated by the identity substitution:
\begin{lemma}[Identity substitution]
  \label{lem:id}
  $\sid \in \Den \Gamma \Gamma$.
\end{lemma}
\begin{proof}
  By induction on $\Gamma$.  In case $\Gamma.A$, we have
  $\sid \in \Den \Gamma \Gamma$ by induction hypothesis, thus, by
  weakening, ${\up} \in \Den\Gamma{\Gamma.A}$.  Further, the 0th de
  Bruijn index $\x_0 \in \Den A {\Gamma.A}$.
  Thus $(\up.\x_0) = \sid \in \Den{\Gamma.A}{\Gamma.A}$.
\end{proof}

The main theorem shows that each well-typed term inhabits the corresponding semantic type:
\begin{theorem}[Fundamental theorem of logical predicates]
  \label{thm:fund}
  If $a : \Gamma \vdash A$ and $\Gs \in \Den \Gamma \Delta$ then $a
  \sigma \in \Den A \Delta$.
\end{theorem}
Normalization is then a direct consequence:
\begin{corollary}[Strong normalization]
  If $a : \Gamma \vdash A$ then $a \in \SN$.
\end{corollary}
\begin{proof}
  By \Cref{thm:fund} with \Cref{lem:id}, $a\, \sid = a \in \Den A
  \Gamma$, thus, $a \in \SN$ since each semantic type contains only
  strongly normalizing terms.
\end{proof}

The definition of the semantic types such as $\A \to \B$ needs be
crafted such as to allow us to prove \Cref{thm:fund}.
In the next section we identify the necessary properties.

\subsection{Modelling the inference rules}

To formulate the properties that allow us to prove \Cref{thm:fund} we
introduce an auxiliary construction $\C[\A]$, ``\emph{abstraction}'',
given semantic types $\A$ and $\C$, where $\A$ classifies terms of
type $A$ and $\C$ terms of type $C$.
\[
  \C[\A]_\Gamma =
  \{ t \in \Gamma.A \vdash C
     \mid t(\tau.a) \in \C_\Delta
     \mbox{ for all } \tau : \Delta \leq \Gamma
     \mbox{ and } a \in \A_\Delta
  \}
  .
\]
%The \emph{abstraction}%
The abstraction%
\footnote{Matthes \cite[Sec.~6.2]{matthes:intersection} uses the
  notation $\mathsf{S}_x(\A,\C)$ for abstraction (in a setting with
  named variables $x$).}
$\C[\A]$ is a presheaf via the weakening with the
lifted OPE:
\begin{lemma}
  If $\tau : \Delta \leq \Gamma$ and $t \in \C[\A]_\Gamma$ then
  $t(\Up\tau) : \C[\A]_\Delta$.
\end{lemma}
\begin{proof}
  Assume $\tau' : \Phi \leq \Delta$ and $a \in \A_\Phi$ and show
  $t(\Up\tau)(\tau'.a) \in \C_\Phi$.  Since $(\Up\tau)(\tau'.a) =
  \tau\tau'.a$ this follows by definition of $t \in \C[\A]_\Gamma$.
\end{proof}

Using abstraction, the properties of the semantic connective can be
mechanically obtained from the inference rules for the syntactic
connective.  In the formulation of these properties, a judgement $a :
\Gamma \vdash A$ turns into statement $a \in \A_\Gamma$ and a
judgement $t : \Gamma.A \vdash C$ into $t \in \C[\A]_\Gamma$.
In case of semantic implication $\A \to \B$, we obtain the following
four requirements, one for each rule:
%% Using abstraction, the properties of the semantic implication $\A \to
%% \B$ can be mechanically obtained from the inference rules connected to
%% implication.
\begin{itemize}%[leftmargin=3em] %enumitem
\setlength{\itemindent}{2.7em}

\item[\namedlabel{it:in00}{\rm(\inn\to{00})}]
  If $t \in (\A \to \B)[\A]$ and $u \in (\A \to \B)[\B]$ then
  $\inn\to{00}(t,u) \in \A \to \B$.

\item[\namedlabel{it:in01}{\rm(\inn\to{01})}]
  If $t \in (\A \to \B)[\A]$ and $b \in \B$ then
  $\inn\to{01}(t,b) \in \A \to \B$.

\item[\namedlabel{it:in11}{\rm(\inn\to{11})}]
  If $a \in \A$ and $b \in \B$ then $\inn\to{11}(a,b) \in \A \to \B$.

\item[\namedlabel{it:el10}{\rm(\el\to{10})}]
  If $f \in \A \to \B$ and $a \in \A$ and $t \in \C[\B]$ then
  $f \cdot \el\to{01}(a,t) \in \C$.

\end{itemize}

Given these properties of semantic implication, we can show that
semantic types model the inference rules:

\begin{proof}[Proof of \Cref{thm:fund}]
  By induction on $t : \Gamma \vdash C$, prove $t\Gs \in \Den C \Delta$ for
  all $\Gs \in \Den \Gamma \Delta$.
  In case of a variable $t = x$, we have
  $x\Gs \in \Den{\Gamma(x)}\Delta$ by assumption on $\Gs$.

  The other cases are covered by the assumptions on semantic
  implication.  For instance, consider:
  \[
  \ru{t : \Gamma.A \vdash A \to B \qquad
      b : \Gamma \vdash B
    }{\inn\to{01}(t,b) : \Gamma \vdash A \to B
    }
  \]
  By induction hypothesis (2) $b\sigma \in \Den B \Delta$ and
  (1) $t(\sigma\tau.a) \in \Den{A \to B}\Phi$
  for arbitrary $\tau : \Phi \leq \Delta$ and $a \in \Den A \Phi$,
  since then $\sigma\tau \in \Den\Gamma\Phi$.
  Hence,
  $t(\Up\sigma) \in (\den{A \to B})[\den A]_\Delta$
  by definition of abstraction.
  By property \ref{it:in01}, if follows that
  $\inn\to{01}(t,b)\sigma = \inn\to{01}(t(\Up\sigma),b\sigma) \in \Den{A \to B}\Delta$.
\end{proof}

This completes the description of our framework for strong normalization proofs.
We now turn our attention to ways how to instantiate this framework.

\subsection{Flavors of semantic types}
\label{sec:flavors}

We are familiar with three principal methods how to construct semantic types for
strong normalization proofs.
\begin{enumerate}

\item \emph{Saturated sets} following Tait
  \cite{tait:functionalsFiniteTypeI}, see \eg the exposition by Luo
  \cite{luo:thesis}.
  This technique requires semantic types to be closed under weak head
  expansion and is only known to work for deterministic weak head
  reduction.
  While it has been applied \cite{geuversHurkens:icla17} to the
  \emph{if-then-else} instance of ITTND with optimized rules,
  it does not cover the general case of TTND with
  non-deterministic and even non-confluent weak head reduction.

\item \emph{Reducibility candidates} following Girard
  \cite{girard:thesis,girardLafontTaylor:proofsAndTypes}.  We apply
  this method in \Cref{sec:cr}.
  It covers $\beta$-reduction but not $\beta\pi$.

\item \emph{Biorthogonals} that have been used in SN proofs for
  $\lambda$-calculi for classical logic, e.g. by Parigot \cite{parigot:jsl97},
  and in SN proofs for the monadic meta-language by Lindley and Stark
  \cite{lindleyStark:tlca05}.
  These cover even $\beta\pi$, and we shall turn to these in \Cref{sec:biortho}.
\end{enumerate}


\section{Reducibility Candidates}
\label{sec:cr}

Girard's reducibility candidates are a flavor of semantic types that
can show strong normalization also for non-confluent rewrite relations
such as reduction in truth-table natural deduction.

When defining the semantic versions of the logical connectives such as
$\A \to \B$, we have the choice to base the definition either on the
introduction rules or the elimination rules.%
\footnote{See Matthes' \cite[Section 6.2]{matthes:intersection}
  systematic exposition of introduction-based vs.\ elimination-based
  definition of semantic types (in the context of the saturated sets method).}
We will study both
approaches, but first, we recapitulate the definition of reducibility
candidates.

Let $\Intro$ be the term set of introductions, \ie, the terms of
the form $\tin^{\vec b}_c(\vec t)$.  This set is clearly closed under
weakening and anti-weakening.

A \emph{reducibility candidate} $\A$ for a type $A$
is a term set family
%  is a context-indexed
% family of predicates on terms of type $A$, written as sets,
with the following properties:
\begin{itemize}%[leftmargin=3em]
\setlength{\itemindent}{2.7em}

% \item[\namedlabel{it:cr0}{CR0}]
%   If $a \in \A_\Gamma$ and $\tau : \Delta \leq \Gamma$ then
%   $a\tau \in \A_\Delta$.

\item[\namedlabel{it:cr1}{CR1}]
  $\A\indy\Gamma \subseteq \SN$.

\item[\namedlabel{it:cr2}{CR2}]
  If $a \in \A\indy\Gamma$ and $a \red a'$ then $a' \in \A\indy\Gamma$.

\item[\namedlabel{it:cr3}{CR3}]
  For $a : \Gamma \vdash A$,
  % if $a \in \SN \setminus \Intro$
  if $a \not\in \Intro$
  and $(a \red \_) \subseteq \A\indy\Gamma$, then $a \in \A\indy\Gamma$.

\end{itemize}
We write $\A \in \CR$ if $\A$ is a term set family satisfying CR1-3.
It is easy to see that $\SN \in \CR$.
If $\A$ satisfies only CR1/2, it shall be called a \emph{precandidate}.

Term set abstraction operates on precandidates:
\begin{lemma}[Abstraction]
\label{lem:abs}
  Let $\A_\Gamma$ be inhabited for any $\Gamma$.
  If $\C$ is a precandidate, so is $\C[\A]$.
 % satisfies CR1/2 and is
 %  closed under lifted weakening (almost \ref{it:cr0}).
\end{lemma}
\begin{proof}
  \ref{it:cr1} holds by non-emptiness of $\A$:
  Given $t \in \C[\A]_\Gamma$ and
  arbitrary $a \in \A_\Gamma$ we have $t[a] \in \C_\Gamma$.  In
  particular, $t[a] \in \SN$, and thus, $t \in \SN$.

  \ref{it:cr2} relies on the closure of reduction
  under substitution:  Assume $\C[\A]_\Gamma \ni t \red t'$ and $\tau
  : \Delta \leq \Gamma$ and $a \in \A_\Delta$.  To show $t'(\tau.a)
  \in \C_\Delta$ observe that $t(\tau.a) \in \C_\Delta$ and that \ref{it:cr2}
  holds for $\C$.
\end{proof}

\begin{remark}[On emptyness of RCs]
  In untyped presentations of RCs, \ref{it:cr3} guarantees
  non-emptyness of any $\A \in \CR$, since automatically all variables
  will inhabit $\A$ by virtue of \ref{it:cr3}.  In our case, $\A_\Gamma$
  may be empty since there may be no variables $x : \Gamma \vdash a$
  of the correct type $a$.  We thus have to be a bit careful when
  carrying over the textbook proofs
  \cite{girardLafontTaylor:proofsAndTypes}
  to our intrinsically-typed setting.
\end{remark}


\subsection{Elimination-based approach}
\label{sec:elimbased}

Geuvers and Hurkens \cite{geuversHurkens:types17} base the semantic
definition of the logical connective on the elimination rules.
A term inhabits a semantic type if it can be soundly eliminated by all
possible eliminations for that type.
In case of implication, % \fbox{$f \in (\A \to \B)_\Gamma$} iff
\[
  f \in (\A \to \B)_\Gamma
  \iff
  \forall \C \in \CR, \,
  \tau : \Delta \leq \Gamma, \,
  a \in \A_\Delta, \,
  t \in \C[\B]_\Delta.\
  f\tau \cdot \el\to{10}(a,t) \in \C_\Delta .
\]
Due to our intrinsic typing,
in contrast to Geuvers and Hurkens \cite{geuversHurkens:types17},
we need \emph{Kripke-style functions space}, \ie,
quantify over all extensions $\Delta$ of $\Gamma$ with
their respective embeddings $\tau : \Delta \leq \Gamma$.
Still, this definition can be mechanically derived from the elimination rules
of implication, which is the single rule:
\[
  \ru{f : \Gamma \vdash A \to B \qquad
      a : \Gamma \vdash A \qquad
      t : \Gamma.B \vdash C
    }{f \cdot \el\to{10}(a,t) : \Gamma \vdash C
    }
\]
In case of several elimination rules, the definition of the semantic
type has to require the closure under all rules \cite{geuversHurkens:types17}.

Note the impredicative quantification over all reducibility candidates
$\C$, which requires an impredicative meta-theory to formalize this
definition.  Such an impredicative quantification is not required in
the introduction-based approach that we study in \Cref{sec:introbased}.

The elimination-based approach gives us the soundness of the
elimination rules for free.
\begin{lemma}[Elimination]
  If $f \in \A \to \B$ and $a \in \A$ and $t \in \C[\B]$ then
  $f \cdot \el\to{10}(a,t) \in \C$.
  (Property \ref{it:el10}.)
\end{lemma}
\begin{proof}
  By definition of $\A \to \B$ using $\tau = \sid$.
\end{proof}

Soundness of the introduction rules requires some work.
\begin{lemma}[Introduction]
  Properties \ref{it:in00}, \ref{it:in01} and \ref{it:in11} hold for
  $\A \to \B$.
\end{lemma}
\begin{proof}
  We show property \ref{it:in01}, the others are analogous.  Assume
  $t \in (\A \to \B)[\A]\ind\Gamma$ and $b \in \B\ind\Gamma$ and show
  $\inn\to{01}(t,b) \in \indp{\A \to \B}{\Gamma}$.  To this end, assume
  $\C \in \CR$ and
  $\tau : \Delta \leq \Gamma$ and
  $a \in \A\indy\Delta$ and $u \in \C[\B]\indy\Delta$ and
  show $v := \inn\to{01}(t,b)\tau \cdot \el\to{10}(a,u) \in \C\indy\Delta$ by
  induction on $t(\Up\tau),b\tau,a,u \in \SN$ (obtained by \ref{it:cr1}).

  Since $v$ is not an introduction we shall utilize \ref{it:cr3} for
  $\C$.  Therefore, we have to show that all reducts of $v$ are
  already in $\C\indy\Delta$.

  If reduction happens in subterm $b\tau$, so $b\tau \red b'$, we can apply
  the induction hypothesis on $b' \in \SN$, since $b' \in \B\indy\Delta$
  by \ref{it:cr2}.  Reduction in one of the other subterms $t,a,u$ of
  $v$ is treated analgously.

  It remains to cover the $\beta$-reductions at the root, which are
  $v \red u[b\tau]$ and $v \red t(\tau.a) \cdot \el\to{10}(a,u)$.
  We have $u[b\tau] \in \C\indy\Delta$ by assumptions on $u$ and $b$.  Further, since
  $t(\tau.a) \in \indyp{\A \to \B}{\Delta}$, by definition $t(\tau.a) \cdot
  \el\to{10}(a,u) \in \C\indy\Delta$.
\end{proof}

Let us not forget to verify that $\A \to \B$ is indeed a reducibility
candidate.
\begin{lemma}[Function space]
  \label{lem:funcr}
  If $\A,\B \in \CR$ then $(\A \to \B) \in \CR$.
\end{lemma}
\begin{proof}
  First, $\A \to \B$ needs to be a term set family.
  This is facilitated by the Kripke-style definition of the function space:
  Assume $f \in (\A \to \B)_\Gamma$ and $\tau : \Delta \leq \Gamma$
  and show $f \tau \in (\A \to \B)_\Delta$.  To this end assume $\C
  \in \CR$ and $\tau' \in \Phi \leq \Delta$ and $a \in \A_\Phi$ and $t
  \in \C[\B]_\Phi$ and show $f\tau\tau' \cdot \el\to{10}(a,t) \in
  \C_\Phi$.  This follows from the assumption on $f$ with OPE
  $\tau\tau' : \Phi \leq \Gamma$.

  For \ref{it:cr1}, assume $f \in (\A \to \B)_\Gamma$ and show $f \in \SN$.
  Let $\C = \A$ (this choice is simplest, but any RC would do) and
  $\Delta = \Gamma.A$.  Clearly $a := (\x_0 : \Delta \vdash A) \in
  \A_\Delta$ and $t := (\x_1 : \Delta.B \vdash A) \in \C[\B]_\Delta$.
  Thus $f\tau \cdot \el\to{10}(a,t) \in \C_\Delta \subseteq \SN$.
  This implies $f \in \SN$.

  Closure under reduction (\ref{it:cr2}) follows because reduction is
  closed under weakening and elimination.

  For \ref{it:cr3}, assume $f : \Gamma \vdash A \to B$ that is not an
  introduction and whose reducts are in $(\A \to \B)_\Gamma$.  To show
  $f \in (\A \to \B)_\Gamma$, assume $\C \in \CR$ and $\tau : \Delta \leq \Gamma$ and
  $a \in \A_\Delta$ and $t \in \C[B]_\Delta$ and show $f\tau \cdot E \in
  \C_\Delta$ where $E = \el\to{10}(a,t)$.  We proceed by \ref{it:cr3}
  for $\C$, exploiting that $f\tau \cdot E$ is not an introduction
  either.  It is sufficient to show that all reducts of $f\tau \cdot
  E$ are in $\C_\Delta$.  We proceed by induction on $a,t \in \SN$.
  Since $f$ is not an introduction, we can only reduce in $f$ or in $E$.
  Reductions in $f$ are covered by the assumption on $f$.
  Reductions in $E$ are either $a \red a' $ or $t \red t'$ and covered by the
  respective induction hypothesis, since $a'$ and $t'$ stay in their
  respective RCs by virtue of \ref{it:cr2}.
\end{proof}

Strong normalization now follows according to \Cref{sec:model}.

\subsection{A gap in the proof by Geuvers and Hurkens}
\label{sec:gap}

In their elimination-based SN proof, Geuvers and Hurkens
\cite[Section~6.1]{geuversHurkens:types17} use for semantic types
saturated sets with the expansion closure modified to liken
\ref{it:cr3}.  To explain their approach, let us first introduce weak
head reduction% (called \emph{key reduction} in \loccit),
\footnote{Weak head reduction is called \emph{key reduction} in \loccit.}
$I \cdot E \cdot \vec E \whd[\beta] v \cdot \vec E$ where
$\beta$-redex $I \cdot E$ contracts to $v$ and the elimination
sequence $\vec E$ is arbitrary (can be empty).  Any SN term that is
not a $\whd[\beta]$-redex is called neutral (set $\Neut$).

In Def.~57.3 \cite{geuversHurkens:types17}
a set of terms $\X$ is defined to be saturated ($\X \in
\SAT$) if
\begin{enumerate}[a.]

\item (\namedlabel{it:sat1}{SAT1}) $\X \subseteq \SN$,

\item (\namedlabel{it:sat2}{SAT2}) $\Neut \subseteq \X$, and

\item (\namedlabel{it:sat3}{SAT3$'$}) $\X$ is closed under
  $\whd[\beta]$-expansion, namely if $t \in \SN$ and
  $(t \whd[\beta]\_) \subseteq \X$ (*) then $t \in \X$.

\end{enumerate}
In the original formulation (SAT3) of the saturated sets
method,\footnote{See for instance the exposition by Luo \cite{luo:thesis}.}
the requirement (*) is that $(t \whd[\beta]\_) \cap \X$ is inhabited,
meaning that $t$ is the weak-head expansion of some term that is already
in $\X$.  In the new formulation the requirement is that all
weak-head reducts of $t$ are in $\X$.  It is easy to see that now
\ref{it:sat2} is subsumed under \ref{it:sat3}, since neutrals have
no weak-head reducts, and the condition (*) is trivially satisfied.
The modification of SAT3 towards CR3-style \ref{it:sat3} was perhaps
undertaken to account for the non-determinism of $\whd[\beta]$ in
ITTND.

Unfortunately, with \ref{it:sat3} it is not clear how to show the equivalent of
\Cref{lem:funcr}, $(\A \to \B) \in \SAT$ \cite[Lemma~58]{geuversHurkens:types17}.
In the formulation based on untyped terms, $\A \to \B$ is defined by
\[
  f \in (\A \to \B)
  \iff
  \forall \C \in \SAT, \,
  a \in \A, \,
  t \in \C[\B].\
  f \cdot \el\to{10}(a,t) \in \C .
\]
To attempt to show \ref{it:sat3} for $\A \to \B$, assume $f \in \SN$ with
$(f \whd[\beta]\_) \subseteq \A \to \B$ and derive $f \in \A \to \B$.
To this end, assume $\C \in \SAT$ and $a \in \A$ and $t \in \C[\B]$
and show $f \cdot E \in \C$ with $E = \el\to{10}(a,t)$.  Since $\C$ is
arbitrary, we have to rely on \ref{it:sat3} to introduce elements into
$\C$.  Thus, we need to show (1) $f \cdot E \in \SN$ and (2)
$t' \in \C$ whenever $f \cdot E \whd[\beta] t'$.  For both goals we need to
analyze the reducts of $f \cdot E$.  The problem is that $f$ could be
an introduction and, hence, $f \cdot E$ a $\beta$-redex reducing to
some $v$.  We lack assumptions to show $v \in \C$ and even $v \in
\SN$, since $v$ is not of the same form as $f \cdot E$.  Were it either
$f' \cdot E$ (with $f \red f'$) or $f \cdot E'$ (with $E \red E'$)
there would be some hope to use the assumptions, in particular $f,E \in \SN$.

Note that with the original SAT3 the relevant part of the proof goes
in the other direction, we can exploit the closure of weak head
reduction under elimination, namely if $f \whd[\beta] f'$
then $f \cdot E \whd[\beta] f' \cdot E$.  It seems that this direction
is employed in the proof sketch
\cite[Lemma~58.c]{geuversHurkens:types17}, not matching the new
requirement \ref{it:sat3}.

At the moment, we do not see an easy fix for the arguably more elegant
$\SAT$ method, and have to confine to the more pedestrian $\CR$ method
as laid out in \Cref{sec:elimbased}.  However, we can get rid of the
impredicative definition of $\A \to \B$ and use an inductive
definitions instead.


\subsection{Introduction-based approach}
\label{sec:introbased}

Instead of the impredicative elimination-based definition of sematic
types like $\A \to \B$, we can base the definition on the introduction
rules.  The rough idea is that elements of $\A \to \B$ can be
introduced by any of $\inn\to{00}$, $\inn\to{01}$, and
$\inn\to{11}$---this is a union of reducibility candidates.
However, since the first two of these need already the implication
they introduce, the construction of a least fixed-point is required.

Note that the union $\A \cup \B$ of two reducibility candidates $\A$
and $\B$ preserves CR1/2, but not \ref{it:cr3}.
However,
property \ref{it:cr3} can be forced by the following closure operation $\cl\A$
on a term set $\A \subseteq (\Gamma \vdash A)$.
\begin{gather*}
  \nru{\remb
    }{a \in \A
    }{a \in \cl\A
    }
\qquad
  \nru{\rexp
     }{a : \Gamma \vdash A \qquad
       % a \in \SN \setminus \Intro \qquad
       a \not\in \Intro \qquad
       (a \red \_) \subseteq \cl\A
     }{a \in \cl\A}
\end{gather*}
The closure operation lifts pointwise to families
$\A_\Gamma \subseteq \Gamma \vdash A$ of term sets.
\begin{lemma}
  If $a \in \cl\A_\Gamma$ and $\tau : \Delta \leq \Gamma$ then
  $a \tau \in \cl\A_\Delta$.
\end{lemma}
\begin{proof}
  By induction on $a \in \cl\A_\Gamma$.  In case $a \in \A_\Gamma$
  (\remb) use the functoriality of $\A$ and \remb.
  In case \rexp, \ie, $a \in \SN(\Gamma \vdash A)
  \setminus \Intro$ and $(a \red\_) \subseteq \cl\A_\Delta$ we first
  have $a \tau \in \SN(\Delta \vdash A) \setminus \Intro$.  If $a\tau
  \red b'$ then there is $b$ with $a \red b$ and $b' = b\tau$, and by
  induction hypothesis $b\tau \in \cl\A_\Delta$.  Thus $a\tau \in
  \cl\A_\Delta$ by \rexp.
\end{proof}

\begin{lemma}[Saturation]
  % If $\A$ satisfies CR0-2, then $\cl\A$ is a reducibility candidate.
  $\cl\A$ is a reducibility candidate for any precandidate $\A$.
\end{lemma}
\begin{proof}
  \ref{it:cr3} is forced by the closure operation.
  Closure under reduction (\ref{it:cr2}) and preservation of SN
  (\ref{it:cr1}) are proven by induction on $t \in \cl\A$,
  the latter using that $t \in \SN$ when all its reducts are.
  % and preservation of \ref{it:cr1} and
  % \ref{it:cr2} is immediate.
  % \ref{it:cr0} follows again from anti-weakening of reduction, and that being
  % an introduction is not affected by weakening or anti-weakening.
\end{proof}

% Note that the union $\A \cup \B$ preserves CR1/2, but not \ref{it:cr3}; thus,
% to obtain a reducibility candidate from the union of two such
% candidates we need to apply the closure operation in general.

% Given two term set families $\A$ and $\X$ for types $A$ and $X$,
% resp., let $\X[\A]$ be the term set family defined by
% \[
%   \X[\A]_\Gamma =
%   \{ t \in \Gamma.A \vdash X
%      % t \in \SN(\Gamma.A \vdash X)
%      \mid t(\tau.a) \in \X_\Delta
%      \mbox{ for all } \tau : \Delta \leq \Gamma
%      \mbox{ and } a \in \A_\Delta
%   \}
%   .
% \]
% Herein, $\tau.a : \Delta \vdash \Gamma.A$ is obtained by turning
% $\tau$ into a substitution and extending it by $a$.
% Clearly, $\X[\A]$ is monotone in $\X$. (It is also antitone in $\A$, but we
% shall not utilize that.)

% \begin{lemma}[Abstraction]
%   If $\A$ and $\X$ are reducibility candidates, so is $\X[\A]$.
% \end{lemma}
% \begin{proof}
%   \ref{it:cr0} is guaranteed by the \emph{Kripke}-style definition of $\X[\A]$.
%   \ref{it:cr1} holds by definition, and \ref{it:cr2} relies on the closure of reduction
%   under substitution.

%   For \ref{it:cr3}, let $t \in \SN(\Gamma.A \vdash X) \setminus \Intro$ and
%   $(t \red \_) \subseteq \X[\A]_\Gamma$.
%   % We need to show that $t \in \X[\A]_\Gamma$.  In case that $t$ is de
%   % Bruijn index 0 (and thus X = A)
%   Further, to show that $t \in \X[\A]_\Gamma$, assume
%   $\tau : \Delta \leq \Gamma$ and $a \in \A_\Delta$ and show
%   $t(\tau.a) \in \X_\Delta$.
%   By \ref{it:cr3} for $\X$, we first need to show that $t(\tau.a) \not\in
%   \Intro$.  Since $t \not\in\Intro$, the only possibility for
%   $t(\tau.a) \in \Intro$ is that $t : \Gamma.A \vdash X$ is the 0th de Bruijn index.
%   However, this is excluded by the precondition $A \not=X$.
%   Then, we show $t(\tau.a) \in \SN$
% \end{proof}

% \begin{lemma}[Abstraction]
% \label{lem:abs}
%   Let $\A_\Gamma$ be inhabited for any $\Gamma$.
%   If $\X$ is a precandidate, then so is $\X[\A]$.
%  % satisfies CR1/2 and is
%  %  closed under lifted weakening (almost \ref{it:cr0}).
% \end{lemma}
% \begin{proof}
%   \ref{it:cr1} holds by non-emptiness of $\A$.  Given $t \in \X[\A]_\Gamma$ and
%   arbitrary $a \in \A_\Gamma$ we have $t[a] \in \X_\Gamma$.  In
%   particular, $t[a] \in \SN$, and thus, $t \in \SN$.

%   \ref{it:cr2} relies on the closure of reduction
%   under substitution:  Assume $\X[\A]_\Gamma \ni t \red t'$ and $\tau
%   : \Delta \leq \Gamma$ and $a \in \A_\Delta$.  To show $t'(\tau.a)
%   \in \X_\Delta$ observe that $t(\tau.a) \in \X_\Delta$ and that \ref{it:cr2}
%   holds for $\X$.
% %
%   % For closure under lifted weakening, assume $t \in \X[\A]_\Gamma$ and
%   % $\tau' : \Gamma' \leq \Gamma$ and show $t(\Up\tau') \in \X[\A]_{\Gamma'}$.
%   % (Note that $t : \Gamma.A \vdash X$ and $\Up\tau : \Gamma'.A \leq
%   % \Gamma.A$.)
%   % Assume $\Delta \leq \Gamma'$ and $a \in \A_\Delta$ and show
%   % $t(\Up\tau')(\tau.a) \in \X_\Delta$.  Since $t(\Up\tau')(\tau.a) =
%   % t(\tau'\tau.a)$ and $\tau'\tau : \Delta \leq \Gamma$ we conclude by
%   % $t \in \X[\A]_\Gamma$.
% %
%   % \ref{it:cr0} is guaranteed by the \emph{Kripke}-style definition of $\X[\A]$:
%   % Let $t \in \X[\A]_\Gamma$ and $\tau' : \Gamma' \leq \Gamma$ to show
%   % $t\tau' \in \X[\A]_{\Gamma'}$, assume $\tau : \Delta \leq \Gamma'$
%   % and $a \in \A_\Delta$ and show $t\tau'(\tau,a) \in \X_\Delta$.
% \end{proof}

We may now define a notion of function space on reducibility
candidates based on the introduction rules for implication.  Since
introduction rules are ``recursive'' in general, \ie, may mention the
principal formula in the subsequent of a premise, we need to employ
the least fixed-point operation $\mu$ for monotone operators on the
lattice of reducibility candidates.
We define $\A \to \B = \mu\F$ where
\[
  \F(\X)_\Gamma =
  \cl{\{
    \inn\to{00}(t,u),
    \inn\to{01}(t,b),
    \inn\to{11}(a,b) \mid
      a \in \A_\Gamma,
      b \in \B_\Gamma,
      t \in \X[\A]_\Gamma,
      u \in \X[\B]_\Gamma
  \}}
\]
This operation acts on reducibility candidates:
\begin{lemma}[Function space]
  \label{lem:fun}
  If $\A$ and $\B$ are reducibility candidates, so is $\A \to \B$.
\end{lemma}
\begin{proof}
  It is sufficient to show that $\F$ acts on reducibility candidates.
  Since \ref{it:cr3} is forced, it is sufficient that $\F(\X)$ is a
  precandidate for any candidate $\X$, and this follows mostly from
  \Cref{lem:abs} and the candidateship of $\A$ and $\B$.
  % \ref{it:cr0} is immediate,
  \ref{it:cr1} follows since any reduction of an introduction
  needs to happen in one of the arguments of $\tin$, which are SN.
  \ref{it:cr2} follows by the same observation.
\end{proof}

By definition, $\A \to \B$ models the introduction rules for
implication:
properties \ref{it:in00}, \ref{it:in01} and \ref{it:in11}.
For the elimination rule, property \ref{it:el10}, we have to do a bit of work.
\begin{lemma}[Function elimination]
  \label{lem:app}
  Let $\A,\B,\C$ be candidates.
  If $f \in \indp{\A \to \B}{\Gamma}$ and $a \in \A\ind\Gamma$ and
  $u \in \C[\B]\ind\Gamma$ then $f \cdot E \in \C$
  where $E = \el\to{10}(a,u)$.
\end{lemma}
\begin{proof}
  By main induction on $f \in \indp{\A \to \B}{\Gamma}$.
  \begin{caselist}

    \nextcase (\rexp) $f \not\in \Intro$ and $f \red f'$ implies
    $f' \in \indp{\A \to \B}{\Gamma}$:
    We show $f \cdot E \in \C$ by side induction on $E \in \SN$ via \ref{it:cr3}.
    First, $f \cdot E \not\in\Intro$.
    Assume $f \cdot E \red c$.  Since $f$ is not a introduction, we
    have either $f \red f'$ or $E \red E'$.  In the first case, by
    main induction hypothesis, $f' \cdot E \in \C$.
    In the second case, $f \cdot E' \in \C$ by side induction hypothesis.
    In any case, $c \in \C$.  Since $c$ was arbitrary, $f \cdot E \in
    \C$ by \ref{it:cr3}.

    \nextcase $f = \inn\to{00}(t_1,t_2)$ where
    $t_1 \in (\A \to \B)[\A]\ind\Gamma$ and
    $t_2 \in (\A \to \B)[\B]\ind\Gamma$.
    We show $f \cdot E \in \C$ by side induction on $t_1,t_2,E \in
    \SN$ via \ref{it:cr3}.
    Given $f \cdot E \red c$, there are three cases.  Either $c = f' \cdot
    E$ with $f \red f'$ or $c = f \cdot E'$ with $E \red E'$ or $c =
    t_1[a] \cdot E$.  The first two cases are handled by the side
    induction hypotheses, the last case by main induction hypothesis
    on $t_1[a] \in \indp{\A \to \B}{\Gamma}$.

    \nextcase $f = \inn\to{01}(t_1,b)$ where
    $t \in (\A \to \B)[\A]\ind\Gamma$ and
    $b \in \B\ind\Gamma$.
    We show $f \cdot E \in \C$ by side induction on $t,b,E \in
    \SN$ via \ref{it:cr3}.
    Given $f \cdot E \red c$, there are four cases.  Either $c = f' \cdot
    E$ with $f \red f'$ or $c = f \cdot E'$ with $E \red E'$ or $c =
    t[a] \cdot E$ or $c = u[b]$.  The first two cases are handled by the side
    induction hypotheses, the butlast case by main induction hypothesis
    on $t[a] \in \indp{\A \to \B}{\Gamma}$, and the last case by assumption
    $u \in \C[\B]\ind\Gamma$.

    \nextcase $f = \inn\to{11}(a',b)$ where
    $a' \in \A\ind\Gamma$ and
    $b \in \B\ind\Gamma$.
    We show $f \cdot E \in \C$ by side induction on $a',b,E \in
    \SN$ via \ref{it:cr3}.

    Given $f \cdot E \red c$, there are three cases.  Either
    $c = f' \cdot E$ with $f \red f'$ or $c = f \cdot E'$ with
    $E \red E'$ or $c = u[b]$.  The first two cases are handled by the
    side induction hypotheses and the last case by
    assumption $u \in \C[\B]\ind\Gamma$.
  \popQED
  \end{caselist}
\end{proof}

% The rest, interpretation of types and contexts and the fundamental
% theorem is standard, showing the strong normalization.

% For pure implicational truth table natural deduction, types are formed
% from uninterpreted base types $o$ (propositional variables) and
% function space: $A,B ::= o \mid A \to B$.  Types are interpreted as
% the following reducibility candidates:
% \[
% \begin{array}{lll}
%   \Den o \Gamma & = & \SN(\Gamma \vdash o) \\
%   \Den{A \to B} \Gamma & = & (\den A \to \den B)_\Gamma \\
% \end{array}
% \]
% Contexts $\Gamma$ are interpreted as families of sets of
% substitutions.
% \[
%   \begin{array}{lll}
% \Den \Ge \Delta & = & \Delta \vdash \Ge \\
% \Den{\Gamma.A} \Delta & = & \{ \Gs.a \mid \Gs \in \Den \Gamma \Delta
%                             \mbox{ and } a \in \Den A \Delta \}
%   \end{array}
% \]
% Each well-typed term inhabits the corresponding semantic type:
% \begin{theorem}[Fundamental theorem of logical predicates]
%   \label{thm:fund}
%   If $a : \Gamma \vdash A$ and $\Gs \in \Den \Gamma \Delta$ then $a
%   \sigma \in \Den A \Delta$.
% \end{theorem}
% \begin{proof}
%   By induction on $a : \Gamma \vdash A$.
%   For variables, this follows by assumption on $\Gs$, for implication
%   introductions, by definition of $\A \to \B$, and for implication
%   elimination by \Cref{lem:app}.
% \end{proof}

% \begin{lemma}[Identity substitution]
%   \label{lem:id}
%   $\sid \in \Den \Gamma \Gamma$.
% \end{lemma}
% \begin{proof}
%   By induction on $\Gamma$.  In case $\Gamma.A$, we have
%   $\sid \in \Den \Gamma \Gamma$ by induction hypothesis, thus, by
%   weakening, ${\up} \in \Den\Gamma{\Gamma.A}$.  Further, the 0th de
%   Bruijn index $x_0 \in \Den A {\Gamma.A}$ by \ref{it:cr3} (it is SN and has no
%   reducts).  Thus $(\up.x_0) = \sid \in \Den{\Gamma.A}{\Gamma.A}$.
% \end{proof}

% \begin{corollary}[Strong normalization]
%   If $a : \Gamma \vdash A$ then $a \in \SN$.
% \end{corollary}
% \begin{proof}
%   By \Cref{thm:fund} with \Cref{lem:id}, $a\, \sid = a \in \Den A
%   \Gamma$, thus, $a \in \SN$ by \ref{it:cr1}.
% \end{proof}

The pattern outlined here for implication generalizes to arbitrary
connectives given by truth tables.  Each connective is interpreted as
an operation on candidates, using the least fixed-point of the closure
of the term set generated by the introductions.  Each elimination then
has to be proven sound in a lemma similar to \Cref{lem:app}.

%Geuvers et al.\ also present permutation reductions.
This concludes our study of reducibility candidates to show SN for ITTND.
In the remaining technical
sections, we study the extension of the normalization argument to
permutations.

\section{Permutation Reductions}
\label{sec:perm}

Outer eliminations can be shifted into the negative branches of inner
eliminations.  We write
$h \cdot E \cdot E' \contract[\pi] h \cdot E\{E'\}$ for a permutation
contraction.  The composition $E\{E'\}$ of eliminations moves a weakened
version of $E'$ to the negative branches of $E$.  In the case of
implication, we have
\[
  \el\to{10}(a,u) \{ E' \} = \el\to{10}(a,u \cdot E' \up)
\]
where $\up : \Gamma.B \leq \Gamma$ and
$E' \up$ shall denote the weakening of elimination $E'$ by $\up$.
In particular, $\el\to{10}(a',u') \up = \el\to{10}(a' \up, u' (\Up\up))$.

If in the above display $u$ is an introduction, it may $\beta$-react with $E'$
to eliminate further detours.  Thus, $\pi$-reductions can lead to
significant further normalization.

Just throwing permutation reductions into the mix and replaying the CR
proof for SN-$\beta$ does not work.  The proof of \Cref{lem:app} relies
on the fact that if $f \cdot E \red c$ and $f \not\in \Intro$ then
either $f \red f'$ or $E \red E'$, but the structure of the
elimination $f \cdot E$ is preserved.  However, with permutations, in
case $f = f_0 \cdot E_0$ it could be that $c = f_0 \cdot E_0\{E\}$.
This reduction is not covered by any induction hypothesis.

We cannot arbitrarily tighten the restriction $\_ \not\in \Intro$ in
the formulation of \ref{it:cr3}, since \ref{it:cr3} is used in \Cref{lem:app} to
introduce terms of the shape $f \cdot E$
into a reducibility candidate $\C$.  Such terms need to satisfy the
restriction, therefore we cannot exclude $\pi$-redexes in general: a
priori, $f \cdot E$ could be a $\pi$-redex.

TODO: move definition of elimination typing here (or even further up) and
prove (recall) strong normalization (and confluence) of $\pi$ spine
reduction $\whd[\pi]$ where
\[
  \vec E \cdot E_1 \cdot E_2 \cdot \vec E'
  \whd[\pi]
 \vec E \cdot E_1\{E_2\} \cdot \vec E'
 .
\]

\section{Orthogonality}
\label{sec:biortho}
\label{sec:ortho}

Since the reducibility candidate method does not immediately extend to
permutations, we turn to a more powerful technique: biorthogonals.
Lindley and Stark \cite{lindleyStark:redComput} have observed that
biorthogonals (``$\top\top$-lifting'') deal well with the permutation
reduction for the monadic bind in a strong normalization proof for the
monadic meta-language.  We shall thus adapt this technique, although
it is more demanding on our meta-theory, requiring greatest
fixed-points of non-strictly positive operators.  This is covered by
Knaster and Tarski's fixed-point theorem \cite{tarski:fixpoint}, but
not readily available in type-theoretic proof assistants like Coq
\cite{coq:8120} and
Agda \cite{agda:261}.

In the following, when we speak of context-indexed families, we
implicitly assume that the family is closed under weakening.
% in analogy
% to \ref{it:cr0}.

Semantic types $\A$ shall now be context-indexed families of sets of
evaluation contexts $\vec E$, and we write $a \perp \A_\Gamma$ to
characterize a term $a : \Gamma \vdash A$ as classified by semantic
type $\A$.  The orthogonality relation $\perp$ is defined as
\[
  a \perp \A_\Gamma \defiff
  a \in \A_\Gamma^\perp \defiff
  a \cdot \vec E \in \SN \mbox{ for all } \vec E \in \A_\Gamma
  % \forall \vec E \in \A_\Gamma, a \cdot \vec E \in \SN
  .
\]

To formally talk about evaluation contexts, we introduce a judgement
$E : \Gamma \mid A \vdash C$ to characterize eliminations $E$ from type $A$
into $C$, and extend it to vectors $\vec E : \Gamma \mid A \vdash C$
in the usual way:
\[
  \ru{}{\tid : \Gamma \mid A \vdash A}
\qquad
  \ru{E : \Gamma \mid A \vdash B \qquad
      \vec E : \Gamma \mid B \vdash C
    }{E \cdot \vec E : \Gamma \mid A \vdash C}
\]
Weakening $\vec E \tau$ and substitution $\vec E \sigma$ are defined
in the obvious way.

We demand of semantic types that they contain the identity evaluation
context and only contain strongly normalizing evaluation contexts.
Reductions in contexts can either be in the subterms or can be
$\pi$-contractions along the spine.

More formally, a semantic type $\A_\Gamma$ for syntactic type $A$ at
context $\Gamma$ is a set of \emph{pairs}
$(C, (\vec E : \Gamma \mid A \vdash C))$.
Then $a \perp \A_\Gamma$ is defined as
$a \cdot \vec E \in \SN(\Gamma \vdash C)$
for all $(C, \vec E : \Gamma \mid A \vdash C) \in \A_\Gamma$.
However, we typically
suppress the type component $C$ which is implicitly determined by
$\vec E$.
\begin{lemma}[Semantic types]
  Let $\A$ be a semantic type for $A$.
  \begin{enumerate}
  \item If $x : \Gamma \vdash A$ is a variable, then $x \perp
    \A_\Gamma$.
  \item $\A^\perp \subseteq \SN$.
  \item $\A^\perp$ is closed under reduction.
  \end{enumerate}
\end{lemma}
\begin{proof} \bla
  \begin{enumerate}
  \item Given $(C, \vec E) \in \A_\Gamma$ show $x \cdot \vec E \in
    \SN$.  This holds since the only reductions are in $\vec E$, which
    is required to be SN by definition of semantic types.

  \item Given $t \perp \A_\Gamma$ show $t \in \SN$.
   Since $\tid \in \A_\Gamma$, we have $t \cdot \tid = t \in \SN$.

  \item Given $t \perp \A_\Gamma$ and $t \red t'$ and $\vec E \in \A_\Gamma$ we
    have $t' \cdot \vec E \in \SN$ since $t \cdot \vec E \in \SN$ and
    $t \cdot \vec E \red t' \cdot \vec E$.
  \popQED
  \end{enumerate}
\end{proof}

\noindent
Symmetrically to $\A^\perp$, given a set of terms $\T_\Gamma \subseteq
(\Gamma \vdash A)$ we define
\[
  \T_\Gamma^\perp =
  \{ (C, \vec E : \Gamma \mid A \vdash C) \mid
  a \cdot \vec E \in \SN(\Gamma \vdash C)
  \mbox{ for all } a \in \T_\Gamma \}
  .
\]
Taking the orthogonal of a non-empty SN term set is one way to
construct a semantic type:
\begin{lemma}[Orthogonals are semantic types]
  \label{lem:orthsem}
  If $\T$ is a family of non-empty sets of strongly normalizing terms
  of type $A$, then
  $\T^\perp$ is a semantic type for type $A$.
\end{lemma}
\begin{proof}
  First, $\tid \in \T^\perp$ since $\T \subseteq \SN$.
  Then $\T^\perp \subseteq \SN$ since $\T$ is non-empty.
\end{proof}

It is well-known that orthogonality gives rise to the Galois
connection
\[
  \T^\perp \supseteq \A \iff \T \subseteq \A^\perp
\]
and biorthogonality is a closure operator both on sets of terms $\T
\subseteq \T^{\perp\perp}$ and evaluation contexts
$\A \subseteq \A^{\perp\perp}$.

The abstraction type $\X[\A]$ is now defined by
\[
  \X[\A]_\Gamma =
  \{ (C, (\vec E : \Gamma.A \mid X \vdash C))
     \mid \vec E (\tau.a) \in \X_\Delta
     \mbox{ for all } \tau : \Delta \leq \Gamma
     \mbox{ and } a \perp \A_\Delta
  \}
  .
\]
Abstraction operates on semantic types:
\begin{lemma}[Abstraction, revisited]
  \label{lem:absrev}
  If $\A$ and $\X$ are semantic types for $A$ and $X$, then $\X[\A]$
  is a semantic type for $X$.
\end{lemma}
\begin{proof}
  We first show that
  $(X, (\tid : \Gamma.A \mid X \vdash X)) \in \X[\A]_\Gamma$.
  To this end, assume $\tau : \Delta \leq \Gamma$ and $a \in
  \A_\Delta$ and show $\tid(\tau.a) \in \X_\Delta$.  This is trivial,
  since $\tid(\tau.a) = \tid$ and $\X$ is a semantic type.

  Then, assume $(C, (\vec E : \Gamma.A \mid X \vdash C)) \in
  \X[\A]_\Gamma$ and show $\vec E \in \SN$.
  Choose $\tau = \up : \Gamma.A \leq \Gamma$ and $a = \x_0 \in
  \A_{\Gamma.A}$ the 0th de Bruijn index, then $\vec E (\up,\x_0) =
  \vec E \in \X_{\Gamma.A}$ and hence SN.
\end{proof}
Given two semantic types $\A$ and $\B$, the function space $\A \to \B$
is defined as the \emph{greatest fixpoint} $\nu \F^\perp$ of the
pointwise orthogonal $\F^\perp$ of the operator
\[
  \F(\X)_\Gamma =
  \{
    \inn\to{00}(t,u),
    \inn\to{01}(t,b),
    \inn\to{11}(a,b) \mid
      a \perp \A_\Gamma,
      b \perp \B_\Gamma,
      t \perp \X[\A]_\Gamma,
      u \perp \X[\B]_\Gamma
  \}
  .
\]
In comparison with the reducibility candidate version in
\Cref{sec:cr}, the closure operation has been replaced by
biorthogonality, and we converted $\mu(\F^{\perp\perp})$
to $(\nu(\F^\perp)^\perp)$.  We dropped the outer orthogonalization since
we now compute sets of evaluation contexts, but now $\F$ applies
orthogonalization on $\X$.

\begin{lemma}[Function space, revisited]
  \label{lem:funrev}
  If $\A$ is a semantic type for $A$ and $\B$ one for $B$, then $\A
  \to \B$ is a semantic type for $A \to B$.
\end{lemma}
\begin{proof}
  Applying \Cref{lem:orthsem},
  it is sufficient to show that $\F(\X)$ is a family of non-empty sets
  of SN terms for semantic types $\X$.
  This is the case by assumptions on $\A$, $\B$, and $\X$.
\end{proof}

\begin{lemma}[Function introduction]
  \label{lem:funintro}
  Given
  $a \perp \A_\Gamma$ and
  $b \perp \B_\Gamma$ and
  $t \perp (\A \to \B)[\A]_\Gamma$ and
  $u \perp (\A \to \B)[\B]_\Gamma$,
  we have
    $\inn\to{00}(t,u),
     \inn\to{01}(t,b),
     \inn\to{11}(a,b) \perp (\A \to \B)_\Gamma$.
\end{lemma}
\begin{proof}
  For any of the mentioned introductions $I$ we have
  $I \in \F(\A \to \B)_\Gamma$ by definition of $\F$.
  Since biorthogonalization is a closure operator, we have
  $I \in \F(\A \to \B)^{\perp\perp}_\Gamma$ and thus
  $I \perp \F(\A \to \B)^{\perp}_\Gamma = (\A \to \B)_\Gamma$,
  since $\A \to \B$ is a fixed point of $\F^\perp$.
\end{proof}

\begin{lemma}[Function elimination, preliminary]
  \label{lem:appprelim}
  Let $\A,\B,\C$ be semantic types for $A,B,C$, resp.  If
  $a \perp \A_\Gamma$ and $u \perp \C[\B]_\Gamma$ then
  $E = \el\to{10}(a,u) \in (\A \to \B)_\Gamma$.
  % Let $\A,\B,\C$ be semantic types for $A,B,C$, resp.
  % If $f \perp (\A \to \B)_\Gamma$ and $a \perp \A_\Gamma$ and
  % $u \perp \C[\B]_\Gamma$ then $f \cdot E \perp \C$
  % where $E = \el\to{10}(a,u)$.
\end{lemma}
\begin{proof}
  By coinduction, which means that we can use the coinductive
  hypothesis $E \in (\A \to \B)_\Gamma$ after one step towards the
  goal.
  Note that $E \in \SN$ since $a,u \in \SN$.
  By unfolding of the fixed point, it is sufficient to show $E \in
  \F(\A \to \B)^\perp_\Gamma$.  This means to show $I \cdot E \in \SN$
  for any $I \in \F(\A \to \B)_\Gamma$.
  \begin{caselist}

    \nextcase $I = \inn\to{00}(t,u')$ with
    $t \perp (\A \to \B)[\A]_\Gamma$ and
    $u' \perp (\A \to \B)[\B]_\Gamma$.  We proceed by side induction on
    $t,u',E \in \SN$ and show that all possible reducts of $I \cdot E$
    are SN.
    If reduction occurs in $I$ or $E$, we use the side induction
    hypothesis.
    Otherwise $I \cdot E \contract[\beta] t[a] \cdot E$.  We have
    $t[a] \perp (\A \to \B)_\Gamma$ by assumption on $t$ and
    $E \in (\A \to \B)_\Gamma$ by the coinduction hypothesis.
    Thus, $t[a] \cdot E \in \SN$.

    \nextcase $I = \inn\to{11}(a,b)$ with $a \perp \A_\Gamma$ and
    $b \perp \B_\Gamma$.  Again, we proceed by side induction on
    $a,b,E \in \SN$ and show that all possible reducts of $I \cdot E$
    are SN.
    The only interesting reduction is
    $I \cdot E \contract[\beta] u[b] \perp \C_\Gamma$, thus $u[b] \in
    \SN$.
    Coinduction is not needed in this case.

    \nextcase $I = \inn\to{01}(t,b)$.  In this case we have two
      $\beta$-contractions of $I \cdot E$ which we handle as in the
      previous cases.
  \popQED
  \end{caselist}
\end{proof}

The previous lemma is not strong enough to justify the implication
elimination rule, as from $f \perp (\A \to \B)_\Gamma$ and $E \in (\A
\to \B)_\Gamma$ we only get $f \cdot E \in \SN$, but we need the
stronger $f \cdot E \in \C_\Gamma$.
We need the following stronger lemma.

\begin{lemma}[Function elimination, revisited]
  \label{lem:appprev}
  Let $\A,\B,\C$ be semantic types for $A,B,C$, resp.  If
  $a \perp \A_\Gamma$ and $u \perp \C[\B]_\Gamma$ and
  $E = \el\to{10}(a,u)$ and $\vec E \in \C_\Gamma$ then
  $E \cdot \vec E \in (\A \to \B)_\Gamma$.
  % Let $\A,\B,\C$ be semantic types for $A,B,C$, resp.
  % If $f \perp (\A \to \B)_\Gamma$ and $a \perp \A_\Gamma$ and
  % $u \perp \C[\B]_\Gamma$ then $f \cdot E \perp \C$
  % where $E = \el\to{10}(a,u)$.
\end{lemma}
\begin{proof}
  By coinduction, which means that we can use the coinductive
  hypothesis $E \in (\A \to \B)_\Gamma$ after one step towards the
  goal.  Note that $E \in \SN$ since $a,u \in \SN$.  By unfolding of
  the fixed point, it is sufficient to show
  $E \cdot \vec E \in \F(\A \to \B)^\perp_\Gamma$.  This means to show
  $I \cdot E \cdot \vec E \in \SN$ for any
  $I \in \F(\A \to \B)_\Gamma$.
  We do this by proving that all one-step reducts of $I \cdot E \cdot
  \vec E$ are SN.
  We know that $\pi$ spine reduction $\whd[\pi]$ is strongly
  normalizing, thus we side induct on
  $E \cdot \vec E \in \SN(\whd[\pi])$. This side induction hypothesis
  covers the case that $E \cdot \vec E \whd[\pi] \vec E'$.
  We further side induction on $I,E,\vec E \in \SN$.  By these side
  induction hypotheses, we cover the case of inner reductions, i.e., that reduction occurs in
  $I$, $E$ or $\vec E$.
  It remains to treat the cases of $I \cdot E \contract[\beta] \_$
  by distinguishing the different introduction forms $I$.
  \begin{caselist}

    \nextcase $I = \inn\to{00}(t,u')$ with
    $t \perp (\A \to \B)[\A]_\Gamma$ and
    $u' \perp (\A \to \B)[\B]_\Gamma$.

    % We proceed by a second side induction on
    % $t,u',E, \vec E \in \SN$ and show that all possible reducts of $I
    % \cdot E \cdot \vec E$
    % are SN.
    % If reduction occurs in $I$ or $E$, we use the second side induction
    % hypothesis.

    % If $E \cdot \vec E \whd[\pi] \vec E'$ we use the first side
    % induction hypothesis.

    %Otherwise
    The reduction is $I \cdot E \contract[\beta] t[a] \cdot E$.  We have
    $t[a] \perp (\A \to \B)_\Gamma$ by assumption on $t$ and
    $E \cdot \vec E \in (\A \to \B)_\Gamma$ by the coinduction hypothesis.
    Thus, $t[a] \cdot E \cdot \vec E \in \SN$.

    \nextcase $I = \inn\to{11}(a,b)$ with $a \perp \A_\Gamma$ and
    $b \perp \B_\Gamma$.
    % Again, we proceed by side induction on
    % $a,b,E, \vec E \in \SN$ and show that all possible reducts of $I
    % \cdot E \cdot \vec E$
    % are SN.
    % The only interesting reduction is
    The reduction is
    $I \cdot E \contract[\beta] u[b] \perp \C_\Gamma$, thus $u[b]
    \cdot \vec E \in \SN$.
    Coinduction is not needed in this case.

    \nextcase $I = \inn\to{01}(t,b)$.  In this case we have two
      $\beta$-contractions of $I \cdot E$ which we handle as in the
      previous cases.
  \popQED
  \end{caselist}
\end{proof}

\section{Conclusion}
\label{sec:concl}

\paragraph*{Acknowledgements}  Thanks to Herman Geuvers for explaining
me truth-table natural deduction during a 2018 visit to Nijmegen for
the purpose of Henning Basold's PhD ceremony.  Thanks to Ralph Matthes
for some email discussions on the topics of this article.


%%
%% Bibliography
%%

%% Please use bibtex,

\bibliography{medium}

% \appendix

\end{document}
